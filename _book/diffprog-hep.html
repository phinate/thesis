<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Analysis in High-Energy Physics as a Differentiable Program - 7&nbsp; Data Analysis in High-Energy Physics as a Differentiable Program</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./flow-interp.html" rel="next">
<link href="./ml.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Analysis in High-Energy Physics as a Differentiable Program</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Analysis in High-Energy Physics as a Differentiable Program</a>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container">
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container">
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Fundamentals</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a>
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./physics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Physics background</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./stat-fundamentals.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Statistics, in theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./stat-practical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability and Statistics, in practice</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./diffprog.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Gradient descent</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./autodiff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic differentiation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./ml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Machine learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container">
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Applications</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a>
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./diffprog-hep.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Analysis in High-Energy Physics as a Differentiable Program</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./flow-interp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Signal Model Interpolation using Normalizing Flows</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./sh.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Search for a heavy scalar particle <span class="math inline">\(X\)</span> decaying to a scalar <span class="math inline">\(S\)</span> and a Higgs boson, with final state <span class="math inline">\(b\bar{b}\gamma\gamma\)</span> in the ATLAS detector</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container">
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Appendices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a>
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./neos-extra.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Results when optimizing a neural network observable and binning simultaneously</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>

  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation"><span class="toc-section-number">7.1</span>  Motivation</a>
  <ul class="collapse">
  <li><a href="#sec-simple-anal" id="toc-sec-simple-anal" class="nav-link" data-scroll-target="#sec-simple-anal"><span class="toc-section-number">7.1.1</span>  A simplified analysis example, both with and without uncertainty</a></li>
  </ul></li>
  <li><a href="#making-hep-analysis-differentiable" id="toc-making-hep-analysis-differentiable" class="nav-link" data-scroll-target="#making-hep-analysis-differentiable"><span class="toc-section-number">7.2</span>  Making HEP Analysis Differentiable</a>
  <ul class="collapse">
  <li><a href="#a-simple-example-cut-optimization-with-gradient-descent" id="toc-a-simple-example-cut-optimization-with-gradient-descent" class="nav-link" data-scroll-target="#a-simple-example-cut-optimization-with-gradient-descent"><span class="toc-section-number">7.2.1</span>  A simple example: cut optimization with gradient descent</a></li>
  <li><a href="#examining-a-typical-analysis" id="toc-examining-a-typical-analysis" class="nav-link" data-scroll-target="#examining-a-typical-analysis"><span class="toc-section-number">7.2.2</span>  Examining a typical analysis</a></li>
  <li><a href="#sec-bkde" id="toc-sec-bkde" class="nav-link" data-scroll-target="#sec-bkde"><span class="toc-section-number">7.2.3</span>  Binned density estimation (histograms)</a></li>
  <li><a href="#differentiable-likelihood-construction" id="toc-differentiable-likelihood-construction" class="nav-link" data-scroll-target="#differentiable-likelihood-construction"><span class="toc-section-number">7.2.4</span>  Differentiable likelihood construction</a></li>
  <li><a href="#differentiable-test-statistics-profile-likelihood-ratio" id="toc-differentiable-test-statistics-profile-likelihood-ratio" class="nav-link" data-scroll-target="#differentiable-test-statistics-profile-likelihood-ratio"><span class="toc-section-number">7.2.5</span>  Differentiable test statistics (profile likelihood ratio)</a></li>
  <li><a href="#differentiable-hypothesis-tests" id="toc-differentiable-hypothesis-tests" class="nav-link" data-scroll-target="#differentiable-hypothesis-tests"><span class="toc-section-number">7.2.6</span>  Differentiable hypothesis tests</a></li>
  <li><a href="#sec-inferno" id="toc-sec-inferno" class="nav-link" data-scroll-target="#sec-inferno"><span class="toc-section-number">7.2.7</span>  Bonus: Uncertainties on likelihood parameters</a></li>
  </ul></li>
  <li><a href="#putting-it-all-together" id="toc-putting-it-all-together" class="nav-link" data-scroll-target="#putting-it-all-together"><span class="toc-section-number">7.3</span>  Putting it all together!</a>
  <ul class="collapse">
  <li><a href="#a-quick-aside-on-inferno-vs-neos" id="toc-a-quick-aside-on-inferno-vs-neos" class="nav-link" data-scroll-target="#a-quick-aside-on-inferno-vs-neos"><span class="toc-section-number">7.3.1</span>  A quick aside on INFERNO vs <code>neos</code></a></li>
  </ul></li>
  <li><a href="#sec-neos" id="toc-sec-neos" class="nav-link" data-scroll-target="#sec-neos"><span class="toc-section-number">7.4</span>  <code>neos</code>: End-to-End Optimized Summary Statistics for High-Energy Physics</a>
  <ul class="collapse">
  <li><a href="#example-gaussian-blobs" id="toc-example-gaussian-blobs" class="nav-link" data-scroll-target="#example-gaussian-blobs"><span class="toc-section-number">7.4.1</span>  Example: Gaussian blobs</a></li>
  <li><a href="#sec-neos-issues" id="toc-sec-neos-issues" class="nav-link" data-scroll-target="#sec-neos-issues"><span class="toc-section-number">7.4.2</span>  Practical issues</a></li>
  </ul></li>
  <li><a href="#whats-really-the-best-loss-function" id="toc-whats-really-the-best-loss-function" class="nav-link" data-scroll-target="#whats-really-the-best-loss-function"><span class="toc-section-number">7.5</span>  What’s <em>really</em> the best loss function?</a>
  <ul class="collapse">
  <li><a href="#sec-which-loss-model" id="toc-sec-which-loss-model" class="nav-link" data-scroll-target="#sec-which-loss-model"><span class="toc-section-number">7.5.1</span>  A loss landscape interlude for a two-bin model</a></li>
  </ul></li>
  <li><a href="#gaussian-blobs-again" id="toc-gaussian-blobs-again" class="nav-link" data-scroll-target="#gaussian-blobs-again"><span class="toc-section-number">7.6</span>  Gaussian blobs, again</a>
  <ul class="collapse">
  <li><a href="#bin-observable" id="toc-bin-observable" class="nav-link" data-scroll-target="#bin-observable"><span class="toc-section-number">7.6.1</span>  5-bin observable</a></li>
  <li><a href="#bin-observable-1" id="toc-bin-observable-1" class="nav-link" data-scroll-target="#bin-observable-1"><span class="toc-section-number">7.6.2</span>  20-bin observable</a></li>
  <li><a href="#optimizing-binning-and-neural-network-simultaneously" id="toc-optimizing-binning-and-neural-network-simultaneously" class="nav-link" data-scroll-target="#optimizing-binning-and-neural-network-simultaneously"><span class="toc-section-number">7.6.3</span>  Optimizing binning and neural network simultaneously</a></li>
  </ul></li>
  <li><a href="#whats-next" id="toc-whats-next" class="nav-link" data-scroll-target="#whats-next"><span class="toc-section-number">7.7</span>  What’s next?</a></li>
  <li><a href="#credits" id="toc-credits" class="nav-link" data-scroll-target="#credits"><span class="toc-section-number">7.8</span>  Credits</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Analysis in High-Energy Physics as a Differentiable Program</span></h1>
</div>



<div class="quarto-title-meta">



  </div>


</header>

<p>This is the title track of this thesis, and rightly so; it dominated metrics in both my time spent and headspace given for any of the topics I’ve written about. I feel incredibly privileged to have worked on something like this, which is fairly self-contained, and draws upon themes from both machine learning and statistical inference in order to make headway in addressing a long-standing issue: <em>systematic-aware optimization</em>. What’s even cooler is that it goes further than this, opening up a whole variety of possibilities to optimize with the whole statistical inference procedure in the loop, and rethink the ways in which we can improve our workflows. I hope you enjoy it!</p>
<section id="motivation" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="motivation"><span class="header-section-number">7.1</span> Motivation</h2>
<p>Given the success of the Standard Model, analysis of data from the LHC usually occurs for two reasons:</p>
<ul>
<li>Precisely measuring Standard Model processes to look for small deviations from their predicted values</li>
<li>Searching for new physics signatures as predicted by models beyond the Standard Model</li>
</ul>
<p>When analyzing data in this way, we’ll have lots of free parameters to tune. These can be as simple as a threshold value that you limit the <span class="math inline">\(p_T\)</span> to, or as complicated as the weights and biases that determine a neural network for identifying <span class="math inline">\(b\)</span>-jets. We can of course choose any values for these quantities to do our analysis, but the resulting physics that follows may suffer as a result. As such, we’re likely to try some kind of optimization to improve the answers to our physics questions. How do we do this in practice?</p>
<p>In either case above, there is a notion of <span style="color:#13becf">signal</span> (what you’re looking for) and <span style="color:#ff7f0e">background</span> (everything else). Generally, we then try to choose a parameter configuration that can separate (or discriminate) the signal from the background, allowing us to extract just the data we think is relevant to the physics process we’re looking at. As an example, machine learning models are often trained using the <strong>binary cross-entropy</strong> loss as an objective, which corresponds to optimizing the ability of the model to identify whether an event originated from signal or background processes. A closely related goal is the <strong>Asimov significance</strong> in the case of signal and background event counts <span class="math inline">\(s\)</span> and <span class="math inline">\(b\)</span> with <em>no uncertainty</em> on either quantity. The formula for this stems from assuming a Poisson likelihood function as in <a href="stat-practical.html#sec-hifa"><span>Section&nbsp;3.2</span></a>, and is equal to</p>
<p><span id="eq-asimov-significance"><span class="math display">\[
Z_A = \sqrt{2\sum_{i\in bins}((s_i + b_i)(\log{(1 + s_i / b_i)}) - s_i)}~.
\tag{7.1}\]</span></span></p>
<p>As indicated in the sum, these counts can be spread across different bins in the case where your data is a histogram, but the formula is more commonly reduced to the 1-bin scenario that just deals with the overall numbers of signal and background events. In this case, we can then Taylor expand the logarithm to get</p>
<p><span class="math display">\[Z_A = \sqrt{2((s+b)(s/b + \mathcal{O}(s/b) - s)} \approx s/\sqrt{b}~~~\mathrm{for}~s&lt;&lt;b.\]</span></p>
<p>This makes it much clearer to see that optimizing with respect to <span class="math inline">\(Z_A\)</span> is just a fancier way of trying to increase the amount of signal compared to the amount of background, which is directly analogous to separating signal from background, just as binary cross-entropy would do.</p>
<p>Now, this is all very sensible of course (we want to discover our signal), but this approach has some shortcomings that distance the efficacy of the resulting configuration from our physics goals. A recent review of deep learning in LHC physics <span class="citation" data-cites="deeplhc">(<a href="references.html#ref-deeplhc" role="doc-biblioref">Guest, Cranmer, and Whiteson 2018</a>)</span> lets us in on why:</p>
<blockquote class="blockquote">
<p>(…) tools are often optimized for performance on a particular task that is <strong>several steps removed from the ultimate physical goal</strong> of searching for a new particle or testing a new physical theory.</p>
</blockquote>
<blockquote class="blockquote">
<p>(…) sensitivity to high-level physics questions <strong>must account for systematic uncertainties</strong>, which involve a nonlinear trade-off between the typical machine learning performance metrics and the systematic uncertainty estimates.</p>
</blockquote>
<p>This is the crux of the issue: we’re not accounting for uncertainty. Our data analysis process comes with many sources of systematic error, which we endeavour to model in the likelihood function as nuisance parameters. However, optimizing with respect to any of the above quantities isn’t going to be aware of that process. We need something better.</p>
<p>Okay, I hear you: blah blah this is all just talk… let’s prove this scenario needs addressing with an example!</p>
<section id="sec-simple-anal" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="sec-simple-anal"><span class="header-section-number">7.1.1</span> A simplified analysis example, both with and without uncertainty</h3>
<p>Let’s define an analysis with a predicted number of signal and background events (e.g.&nbsp;from simulation), with some uncertainty on the background estimate. We’ll abstract the analysis configuration into a single parameter <span class="math inline">\(\phi\)</span> like so:</p>
<p><span class="math display">\[s = 15 + \phi \]</span> <span class="math display">\[b = 45 - 2 \phi \]</span> <span class="math display">\[\sigma_b = 0.5 + 0.1\phi^2 \]</span></p>
<p>Note that <span class="math inline">\(s \propto \phi\)</span> and <span class="math inline">\(\propto -2\phi\)</span>, so increasing <span class="math inline">\(\phi\)</span> corresponds to increasing the signal/backround ratio. However, our uncertainty scales like <span class="math inline">\(\phi^2\)</span>, so we’re also going to compromise in our certainty of the background count as we do that. This kind of tradeoff between <span class="math inline">\(s/b\)</span> ratio and uncertainty is important for the discovery of a new signal, so it may be that can’t get away with optimizing <span class="math inline">\(s/b\)</span> alone, as the <span class="math inline">\(p\)</span>-value may be worse!</p>
<p>Let’s start by visualizing the model itself, which we do for three values of <span class="math inline">\(\phi\)</span> as an example in <a href="#fig-simple-model">Figure&nbsp;<span>7.1</span></a>.</p>
<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="fig-simple-model" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-simple-model-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.1: Plot of the predicted counts from our model at three values of <span class="math inline">\(\phi\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Using this very simple histogram, we can form a statistical model as if we’re using <a href="stat-practical.html#sec-hifa"><span>Section&nbsp;3.2</span></a> principles, which would look something like</p>
<p><span id="eq-simplemodel"><span class="math display">\[
p(x | \mu) = \mathrm{Poisson}(x | \mu x^{\mathrm{sig}}  + \gamma x^{\mathrm{bkg}})\,\mathrm{Normal}(y | \gamma, 1)~,
\tag{7.2}\]</span></span></p>
<p>where <span class="math inline">\(\gamma\)</span> is a continuous description of <span class="math inline">\(\sigma_b\)</span> that we get from interpolating between the yields, just like in the HistFactory approach, which has the constraint term <span class="math inline">\(\mathrm{Normal}(y | \gamma, 1)\)</span> attached to penalize fitting a value of <span class="math inline">\(\gamma\)</span> that differs largely from the information provided by <span class="math inline">\(\sigma_b\)</span>.</p>
<p>Using this likelihood, we can calculate the expected discovery <span class="math inline">\(p\)</span>-value by doing a hypothesis test using the observed data as the Asimov dataset for the nominal model <span class="math inline">\(\mu, \gamma = 1\)</span>. We can plot this across all the values of <span class="math inline">\(\phi\)</span>, and see what value gives us the lowest <span class="math inline">\(p\)</span>-value (in practice, scanning over the space is computationally impossible for a given analysis configuration and a complicated model). We do this in <a href="#fig-simple-model-pval">Figure&nbsp;<span>7.2</span></a>, where we include the result using a model both with and without uncertainty. Notice how much the curves differ; if we optimized the model without uncertainty (i.e.&nbsp;optimize for signal/background separation only), we’d end up at the <em>worst</em> solution! This is pathologically constructed of course, but it goes to show that these objectives don’t talk to each other directly.</p>
<div class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div id="fig-simple-model-pval" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-simple-model-pval-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.2: Plot of the calculated <span class="math inline">\(p\)</span>-value from using our statistical model across of <span class="math inline">\(\phi\)</span>, both including the uncertainty and neglecting it.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>If we optimize this analysis then, we want to arrive at the value of <span class="math inline">\(\phi\)</span> at the dotted green line (around ~4.3 or so), which gives us the benefit of rejecting the background hypothesis more strongly when the signal exists in the data. This is made possible if we use the <span class="math inline">\(p\)</span>-value as our objective – it clearly accounts for the uncertainty!</p>
<p>The reason for this makes sense: in these physics likelihoods, we’re careful to include all the details of the systematic uncertainties that we’re able to quantify by constructing nuisance parameters that vary the shape and normalization of the model. From here, to calculate the <span class="math inline">\(p\)</span>-value, we then construct the <strong>profile likelihood ratio</strong> as a test statistic, which accounts for these systematic uncertainties by fitting the value of the nuisance parameters depending on the hypothesis you test (see <a href="stat-fundamentals.html#sec-hyptests"><span>Section&nbsp;2.3.3</span></a> for more).</p>
<p>All this makes the <span class="math inline">\(p\)</span>-value seem like a good candidate for an objective function! So why haven’t we used this already?</p>
<p>As emphasized in <a href="diffprog.html"><span>Chapter&nbsp;4</span></a>, if we want to perform optimization using gradient-based methods,<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> then we need the objective that we optimize to be <em>differentiable</em>. This is not immediately the case for the <span class="math inline">\(p\)</span>-value – we would have to be able to differentiate through all stages of the full calculation, including model building, profiling, and even histograms, which are not generally known for their smoothness. But say we were able to decompose this complicated pipeline into bite-size chunks, each of which we can find a way to take gradients of. What becomes possible then? This begins our view of <strong>data analysis in high-energy physics as a differentiable program</strong>.</p>
<p>In the following sections, we’ll take a collider physics analysis apart step-by-step, then see how we can employ tricks and substitutes to recover gradients for each piece. After that, we’ll explore the ways that we can use the result to perform gradient-based optimization of different parts of the analysis with respect to physics goals. We’ll then do it all at once by <em>optimizing a toy physics analysis from end-to-end</em>, exploring the common example of a summary statistic based on a neural network, accounting for uncertainties all the while.</p>
<!-- ## Related work

The only real analog to what's done in this section is INFERNO [@inferno], a similar method for inference aware optimization. In terms of  -->
<!-- ### How do we optimize in an uncertainty-aware way?

Attempts:
- Asimov sig with assumptions on bkg uncert: [@asimovuncert]
- Learning to pivot: [@pivot]
- Directly incorporate NPs: [@uncert] -->
</section>
</section>
<section id="making-hep-analysis-differentiable" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="making-hep-analysis-differentiable"><span class="header-section-number">7.2</span> Making HEP Analysis Differentiable</h2>
<p>The goal of this section is to study components within a HEP analysis chain that are not typically differentiable, and show that when we overcome this, we can employ the use of gradient-based optimization methods – both to optimize free parameters jointly, and to use objectives we care about. From there, we’ll examine the typical steps needed to calculate the sensitivity of a physics analysis, and see how we can make that whole chain differentiable at once, opening up a way to incorporate the full inference procedure when finding the best analysis configuration.</p>
<p>First, we’re going to jump right in with an example to illustrate how we can take advantage of gradient descent to optimize a typical problem faced in collider physics analyses: choosing the best selection criteria.</p>
<section id="a-simple-example-cut-optimization-with-gradient-descent" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="a-simple-example-cut-optimization-with-gradient-descent"><span class="header-section-number">7.2.1</span> A simple example: cut optimization with gradient descent</h3>
<p>We begin with a toy signal and background distribution over some variable <span class="math inline">\(x\)</span>, where the signal lies as a peak on top of an exponentially decaying background, as shown in <a href="#fig-exp-bkg">Figure&nbsp;<span>7.3</span></a>.</p>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="fig-exp-bkg" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-exp-bkg-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.3: Histogram of a situation with a simple exponentially falling background and a small signal peak.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>A quintessential operation for data filtering in HEP is the simple threshold, also called a <strong>cut</strong>: we keep all data above (or below) a certain value of the quantity we’re concerned with. To increase the significance (e.g.&nbsp;as defined by <a href="#eq-asimov-significance">Equation&nbsp;<span>7.1</span></a>), we can try to remove data such that we increase the overall ratio of signal to background. In <a href="#fig-exp-bkg">Figure&nbsp;<span>7.3</span></a>, it looks like there’s not much signal for low values of <span class="math inline">\(x\)</span>, which motivates us to put a cut at say <span class="math inline">\(x=1\)</span>. We can see the result of applying this cut in <a href="#fig-compare-cut">Figure&nbsp;<span>7.4</span></a>, where we’ve increased the Asimov significance compared to using no cut at all.</p>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div id="fig-compare-cut" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-compare-cut-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.4: Comparing the significance resulting from applying a cut to no cut at all.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>We had a nice go at a guess, but how do we pick the <em>best</em> cut? For this simple problem, it suffices to scan over the different significances we’ll get by cutting at each value of <span class="math inline">\(x\)</span>, then just use the value with the highest significance. Doing this leads to the optimal cut being around <span class="math inline">\(x=1.54\)</span>. <!--

::: {#fig-cut-scan .cell execution_count=5}

::: {#fig-cut-scan-1 .cell-output .cell-output-display execution_count=5}
```
Text(0, 0.5, '$Z_A$')
```

A scan over all cut values to find the best resulting Asimov significance.
:::

::: {.cell-output .cell-output-display}
![](diffprog-hep_files/figure-html/fig-cut-scan-output-2.png){#fig-cut-scan-2}
:::
:::


--> In reality, though, this could be an expensive procedure to do for a wide range of <span class="math inline">\(x\)</span> and for many different cut variables. This prompts the search for some kind of intelligent optimization that can handle large dimensional parameter spaces. Gradient descent is just that! But, to make it work, we need to be able to calculate the gradient of the significance with respect to the cut value – something only possible if the cut itself is differentiable (it isn’t).</p>
<p>To see this, note that cuts are step functions, i.e.&nbsp;logical less than or more than statements. These can be viewed as applying weights to the data – 0 on one side of the threshold, and 1 on the other. If we change the cut value, the events either keep their weight (0 change in significance) or sharply gain/lose their weight value (discrete jump in significance). We would then like to replace this thresholding with a <em>smooth</em> weight assignment such that the cut value varies smoothly with the weights applied. What kind of operation can do this? We have such a candidate in the <em>sigmoid function</em> <span class="math inline">\(1/(1+e^{-x})\)</span>.</p>
<p>Normally, the sigmoid serves as a method to map values on the real line to [0,1], so we leverage this to be used as a cut by applying it to data, which results in a set of weights for each point in [0,1]. (A normal cut does this too, but the weights are all 0 or 1, and you drop the 0s. One could similarly threshold on a minimum weight value here.)</p>
<p>Practically, we introduce slope and intercept terms that control the sigmoid’s <span class="math inline">\(x\)</span> position and how “hard” the cut is: <span class="math inline">\(1/(1+e^{-\mathrm{slope}(x-\mathrm{cut~value}})\)</span>. This slope allows us to control the degree to which we approximate the cut as a thresholding operation, with higher values of the slope meaning less approximation (but this will also increase the variance of the gradients, as we’re getting closer to the discrete situation outlined previously). See the sigmoid plotted with different slopes in <a href="#fig-sigmoid">Figure&nbsp;<span>7.5</span></a>.</p>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div id="fig-sigmoid" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-sigmoid-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.5: Comparing the sigmoid to a regular hard cut for different values of the sigmoid slope.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Now that we have a differentiable cut, we can see what the significance scan looks like for both the differentiable and standard cases, shown in <a href="#fig-cut-scan-2">Figure&nbsp;<span>7.6</span></a>. It’s an interesting plot; there’s a clear smoothing out of the overall envelope of the significance in comparison to using the hard cut. However, the important thing is the <strong>coincidence of the maxima</strong>: when optimizing, we’ll use the differentiable cut, but we’ll plug the value of the cut position from the optimization back in to the hard cut for our actual physics results. This is a very important distinction - <em>we don’t use approximate operations in the final calculation!</em> Moreover, since we can control the degree to which we’re approximating the significance landscape, one could even imagine a fine-tuning of the slope when we’re close to a local minima during optimization, allowing us to make jumps more in-line with the true optimum value (though this is not explored here).</p>
<div class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div id="fig-cut-scan-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-cut-scan-2-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.6: A scan over all cut values to find the best resulting Asimov significance – both for the regular cut, and for the sigmoid.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Now that we’ve done the groundwork, we can do the optimization and see if we converge to the correct result! Using gradient descent and the Adam optimizer with a learning rate of 1e-3, we find the cut shown in <a href="#fig-optimized-cut">Figure&nbsp;<span>7.7</span></a> (we optimize <span class="math inline">\(1/Z_A\)</span> since we’re doing minimization). The significance (calculated with the <em>hard</em> cut) is extremely close to the best possible value, so I’d call this a success!</p>
<div class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div id="fig-optimized-cut" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-optimized-cut-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.7: The resulting cut from optimization compared to the true best cut. Significances in both cases are shown.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="examining-a-typical-analysis" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="examining-a-typical-analysis"><span class="header-section-number">7.2.2</span> Examining a typical analysis</h3>
<p>Now that we’ve looked at an example of the kind of thing we may want to do, we can zoom out and look at the big picture. Given a pre-filtered dataset, a commonly used analysis pipeline in HEP involves the following stages:</p>
<ol type="1">
<li><p>Construction of a learnable 1-D summary statistic from data (with parameters <span class="math inline">\(\varphi\)</span>)</p></li>
<li><p>Binning of the summary statistic, e.g.&nbsp;through a histogram</p></li>
<li><p>Statistical model building, using the summary statistic as a template</p></li>
<li><p>Calculation of a test statistic, used to perform a frequentist hypothesis test of signal versus background</p></li>
<li><p>A <span class="math inline">\(p\)</span>-value (or <span class="math inline">\(\mathrm{CL_s}\)</span> value) resulting from that hypothesis test, used to characterize the sensitivity of the analysis</p></li>
</ol>
<p>We can express this workflow as a direct function of the input dataset <span class="math inline">\(\mathcal{D}\)</span> and observable parameters <span class="math inline">\(\varphi\)</span>:</p>
<p><span id="eq-neos"><span class="math display">\[
    \mathrm{CL}_s = f(\mathcal{D},\varphi) = (f_{\mathrm{sensitivity}} \circ f_{\mathrm{test\,stat}} \circ f_{\mathrm{likelihood}}  \circ f_{\mathrm{histogram}}  \circ f_{\mathrm{observable}})(\mathcal{D},\varphi).
\tag{7.3}\]</span></span></p>
<p>Is this going to be differentiable? To calculate <span class="math inline">\(\partial \text{CL}_s / \partial \varphi\)</span>, we’ll have to split this up by the chain rule into the different components, which can be written verbosely as</p>
<p><span id="eq-analysis-chain-rule"><span class="math display">\[
\frac{\partial\,\mathrm{CL}_s}{\partial \varphi} = \frac{\partial f_{\mathrm{sensitivity}}}{\partial f_{\mathrm{test\,stat}}}\frac{\partial f_{\mathrm{test\,stat}}}{\partial f_{ \mathrm{likelihood}}} \frac{\partial f_{\mathrm{likelihood}}}{\partial f_{\mathrm{histogram}}}   \frac{\partial f_{\mathrm{histogram}}}{\partial f_{\mathrm{observable}}}  \frac{\partial f_{\mathrm{observable}}}{\partial \varphi}~.
\tag{7.4}\]</span></span></p>
<p>In the case of an observable that has well-defined gradients with respect to <span class="math inline">\(\phi\)</span> (e.g.&nbsp;a neural network), the last term in <a href="#eq-analysis-chain-rule">Equation&nbsp;<span>7.4</span></a> is possible to calculate through automatic differentiation. But none of the other terms are differentiable by default! We’re going to have to figure out some way to either <em>relax</em> (make differentiable) these operations, or use tricks to make the gradient easier to calculate. This is explored in the following sections, starting with the histogram.</p>
</section>
<section id="sec-bkde" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="sec-bkde"><span class="header-section-number">7.2.3</span> Binned density estimation (histograms)</h3>
<p>Histograms are discontinuous by nature. They are defined for 1-D data as a set of two quantities: intervals (or <em>bins</em>) over the domain of that data, and counts of the number of data points that fall into each bin. For small changes in the underlying data distribution, bin counts will either remain static, or jump in integer intervals as data migrate between bins, both of which result in ill-defined gradients. Similarly to the cut example with the sigmoid, we’re assigning a number (there the weight, and here a count in a bin) in a discrete way to the data – to make this differentiable, we need to come up with a smooth version of this that allows gradients to be calculated across the result.</p>
<p>To say a little more to that effect, we’ll look at the types of gradients that we may be interested in. Say we have a data distribution that depends on some latent parameter <span class="math inline">\(\mu\)</span>, e.g.&nbsp;data that’s drawn from <span class="math inline">\(\mathrm{Normal}(\mu, 1)\)</span>. We can then make a histogram of the resulting data. What happens to that histogram When we shift the value of <span class="math inline">\(\mu\)</span>? Well, shifting the mean will just translate the histogram along the <span class="math inline">\(x\)</span>-axis; an example of this is shown in <a href="#fig-hist-mus">Figure&nbsp;<span>7.8</span></a> for a couple values of <span class="math inline">\(\mu\)</span> (with the random seed kept constant).</p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div id="fig-hist-mus" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-hist-mus-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.8: Translating a histogram from left to right by varying the center of the distribution the data is drawn from.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Let us now shift our focus to a single bin: we’ll choose the bin centered on 0, and monitor its height as we vary <span class="math inline">\(\mu\)</span>, shown in <a href="#fig-bin-height-mu">Figure&nbsp;<span>7.9</span></a>.</p>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<div id="fig-bin-height-mu" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-bin-height-mu-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.9: Demonstrating the shift in the central histogram bin as <span class="math inline">\(\mu\)</span> is varied from -2 to 2.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>We can see that the bin height jumps around in discrete intervals as we translate the underlying data, which would produce ill-defined gradient estimates if we used something numerical like finite differences. To exploit the magic of automatic differentiation here, we want to make some other function such that this envelope becomes smooth; varying <span class="math inline">\(\mu\)</span> by a very small amount should also vary the bin height by a small amount instead of leaving it static or jumping discontinuously.</p>
<p>The solution that we developed to address this involves a <strong>kernel density estimate</strong> (KDE). We discussed this in <a href="stat-practical.html#sec-kde"><span>Section&nbsp;3.1.2</span></a>, but just to recap: a KDE is essentially the average of a set of normal distributions centered at each data point, with their width controlled by a global parameter called the <strong>bandwidth</strong>. There’s a neat way to take this and cast it into a bin-like form (i.e.&nbsp;defined over intervals): We can calculate the “count” in an interval by taking the area under the KDE between the interval endpoints. We can do this using the cumulative density function (cdf), as <span class="math inline">\(P(a \leqslant X \leqslant b) = P(X \leqslant b) - P(X \leqslant a)\)</span>. Since the KDE is the mean over some normal distributions, its cdf is also just the mean of the cdfs for each normal distribution. Moreover, to turn this into a histogram-like object, we can multiply the result by the total number of events, which just changes the mean into a sum. We put this all together in <a href="#fig-bkde-code">Figure&nbsp;<span>7.10</span></a>, where a pseudocoded implementation of a <strong>binned KDE</strong> (bKDE) can be found.</p>
<div id="fig-bkde-code" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bKDE(data: Array, bins: Array, bandwidth: <span class="bu">float</span>) <span class="op">-&gt;</span> Array:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    edge_hi <span class="op">=</span> bins[<span class="dv">1</span>:]  <span class="co"># ending bin edges ||&lt;-</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    edge_lo <span class="op">=</span> bins[:<span class="op">-</span><span class="dv">1</span>]  <span class="co"># starting bin edges -&gt;||</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get cumulative counts (area under kde) for each set of bin edges</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    cdf_hi <span class="op">=</span> norm.cdf(edge_hi.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), loc<span class="op">=</span>data, scale<span class="op">=</span>bandwidth)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    cdf_lo <span class="op">=</span> norm.cdf(edge_lo.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), loc<span class="op">=</span>data, scale<span class="op">=</span>bandwidth)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (cdf_hi <span class="op">-</span> cdf_lo).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># sum cdfs over each kernel</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.10: <strong>?(caption)</strong></figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<div id="fig-bin-height-bkde" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-bin-height-bkde-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.11: Demonstrating the shift in the central histogram bin as <span class="math inline">\(\mu\)</span> is varied from -2 to 2 for both a regular histogram and a bKDE.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Using this, we can remake the plot from <a href="#fig-bin-height-mu">Figure&nbsp;<span>7.9</span></a> for the bKDE, which we can see in <span class="quarto-unresolved-ref">?fig-bin-height-bKDE</span>, showing that the variation of the bin height with <span class="math inline">\(\mu\)</span> is much more well-behaved.</p>
<section id="choosing-the-bandwidth" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="choosing-the-bandwidth">Choosing the bandwidth</h4>
<p>I’ll show a few studies here that illustrate what happens to the accuracy of the bKDE histogram from the perspective of both the distribution and the resulting gradients.</p>
<p>We know what happens to a KDE when we change the bandwidth: small bandwidth gives a function with high variance, and a large bandwidth oversmooths the distribution. How do these effects impact the bKDE? We can quantify this <em>relative to the bin width</em> by examining the shape of the bKDE relative to a “hard” histogram, which is shown in <a href="#fig-bkde-bandwidth">Figure&nbsp;<span>7.12</span></a>. For low bandwidths, we recover something almost resembling a regular histogram. In fact, in the limit of zero bandwidth, we will <em>exactly</em> get a histogram! The reason is that zero bandwidth would turn each normal distribution into an infinite spike at each data point, which, when integrated over to get the counts, would have a contribution of 1 if the event lies in the bin, and 0 otherwise<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div id="fig-bkde-bandwidth" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/relaxed_hist.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.12: Illustration of the bias/smoothness tradeoff when tuning the bandwidth of a bKDE, defined over 200 samples from a bi-modal Gaussian mixture. All distributions are normalized to unit area. The individual kernels that make up the KDE are scaled down for visibility.</figcaption><p></p>
</figure>
</div>
<p>This idea of a bias/variance tradeoff with the bandwidth is the gist of it, but there’s an additional factor that will influence the value of the bandwidth chosen: the number of data samples available. We may expect that as we add more samples to a KDE, there will be a lot more kernels centered on the new points, so we’d want to reduce the bandwidth in order to faithfully represent the envelope of the distribution. We then can inspect the degree to which this also continues to hold for the bKDE; it may be that good defaults for KDEs differ slightly compared to those for bKDEs.</p>
<p>First, let’s examine the distribution accuracy as a function of bandwidth and number of data samples. We can define this by looking at the “true” histogram, which can be calculated using the cumulative distribution of <span class="math inline">\(\mathrm{Normal}(\mu, 1)\)</span> in a way analagous to the bKDE (i.e.&nbsp;the integral under the curve over the intervals defined by the bins), which we then normalize to the number of data samples available. We can then plot the true height of the central bin as it varies with <span class="math inline">\(\mu\)</span>, and compare it to that obtained from the histogram and bKDE estimates across a number of different settings for the sample size and bandwidth. These plots are shown in <a href="#fig-bin-height-all">Figure&nbsp;<span>7.13</span></a>, which looks at bandwidths of 0.05, 0.5, and 0.8 in tandem with sample sizes of 20, 100, and 5000. As expected, we see that the low bandwidth case has the histogram and bKDE predictions for the bin mostly agreeing, while they diverge for larger bandwidths. The best-case scenario appears to be when we have a large number of samples and a low bandwidth, which is when we’d expect all three estimates to converge. If we choose a bandwidth too large though, we’re going to introduce a bias as we oversmooth the data features.</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display">
<div id="fig-bin-height-all" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-bin-height-all-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.13: Demonstrating the shift in the central histogram bin as a function of bandwidth and the number of samples for a histogram and bKDE, which are compared to the true bin height.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>So far things seem all to follow intuition somewhat, but we’ve only checked half the picture; the whole reason we’re using the bKDE construct in the first place is so we can access <em>gradients</em> of the histogram yields. To study these, we can derive the “true” gradients from the definition of the bin height: as before, a bin defined by <span class="math inline">\((a,b)\)</span> for a given <span class="math inline">\(\mu\)</span> value is just</p>
<p><span class="math display">\[\operatorname{yield}_{\mathsf{true}}(\mu; a,b) = \Phi(b;\mu, \sigma) - \Phi(a;\mu, \sigma) ~,\]</span></p>
<p>where <span class="math inline">\(\Phi(x; \mu, \sigma)\)</span> is the normal cumulative distribution parametrized by <span class="math inline">\(\sigma, \mu=\)</span>. We can then just take the gradient of this expression with respect <span class="math inline">\(\mu\)</span> by hand. First we write the explicit definition of the cdf:</p>
<p><span class="math display">\[\Phi(x; \mu, \sigma) = \frac{1}{2}\left[1+\operatorname{erf}\left(\frac{x-\mu}{\sigma \sqrt{2}}\right)\right]~,\]</span></p>
<p>where the convenient short hand of the error function <span class="math inline">\(\operatorname{erf}\)</span> is given by</p>
<p><span class="math display">\[
\operatorname{erf}(x) \equiv \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} d x~.
\]</span></p>
<p>Then, the derivative is as follows:</p>
<p><span class="math display">\[\frac{\partial}{\partial\mu}\Phi(x;\mu, \sigma) = \frac{1}{2}\left[1-\left(\frac{2}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\right)\right]~,\]</span></p>
<p>since <span class="math inline">\(\frac{d}{dx} \operatorname{erf}(x)=\frac{2}{\sqrt{\pi}} e^{-x^{2}}\)</span>.</p>
<p>As mentioned, we have <span class="math inline">\(\sigma=1\)</span> in this particular example, making this expression simpler:</p>
<p><span class="math display">\[ \frac{\partial}{\partial\mu}\Phi(x;\mu, \sigma=1) = \frac{1}{2}\left[1-\left(\frac{2}{\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2}}\right)\right]~.\]</span></p>
<p>Putting this all together gives us</p>
<p><span class="math display">\[\Rightarrow \frac{\partial}{\partial\mu}\operatorname{yield}_{\mathsf{true}}(\mu; a,b) = -\frac{1}{\sqrt{2\pi}}\left[\left(e^{-\frac{(b-\mu)^2}{2}}\right) - \left( e^{-\frac{(a-\mu)^2}{2}}\right)\right]~,\]</span></p>
<p>which we can use as a way to quantify the accuracy of the gradients obtained from using a bKDE compared to those of the amount of the true distribution in the interval <span class="math inline">\((a,b)\)</span>.</p>
<p>The comparative plots between the true gradient, the histogram gradient, and the bKDE gradient are shown in <a href="#fig-bin-grad-all">Figure&nbsp;<span>7.14</span></a>, where the histogram gradient is calculated using the finite differences method, and the bKDE gradient with automatic differentiation. A similar trend can be seen to <a href="#fig-bin-height-all">Figure&nbsp;<span>7.13</span></a>, where the estimate from the bKDE improves with more samples, and becomes much less noisy. This is in contrast to the histogram, which struggles with gradients unless the sample size is large (here 5000), and produces very high variance estimates in general. The bKDE, however, is able to avoid this high variance while keeping a reasonably low bias depending on how many samples are present; the central plot, for instance, shows a case where the bKDE of bandwidth 0.5 far outperforms estimating the true gradient with just 100 samples compared to the erratic estimates using the regular histogram.</p>
<div class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<div id="fig-bin-grad-all" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="diffprog-hep_files/figure-html/fig-bin-grad-all-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.14: Variation of the gradient of the central histogram bin as a function of bandwidth and the number of samples for a histogram and bKDE, which are compared to the true gradient of the yield.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>It seems then that there is some kind of middle ground to be had with respect to the bandwidth one can choose for a bKDE depending on the number of samples present, where the trends of distribution and gradient accuracy roughly align. Optimality seems to be in the high-sample and low-bandwidth case. To look at this at scale, we can summarize each of these plots into a single number, e.g.&nbsp;the mean relative error, and see how this number varies across a large grid of different configurations for the number of samples and the bandwidth. This plot can be found in <a href="#fig-grad-errors">Figure&nbsp;<span>7.15</span></a>, where a number of grid points are taken for combinations of bandwidth/sample size, and the absolute relative error in the gradient has been calculated (and averaged across three random seeds, then a second averaging over 500 values of <span class="math inline">\(\mu\)</span> in (-2,2)). Orange scatter points are overlayed to show the bandwidth choice that yields the minimum relative error given each of the studied sample sizes. The trend is generally in agreement with that which we saw in <a href="#fig-bin-grad-all">Figure&nbsp;<span>7.14</span></a> of higher sample size letting us choose lower bandwidths, but there’s definitely a little pause for thought given the couple points that deviate from forming a neat straight line. There also appears to be a little pocket of lower error around 2000 samples, which doesn’t appear to have any obvious explanation. Given more time, one could study this in detail with a much finer grid (memory and temporal limitations prevented expanding this further), and for a variety of different examples, then maybe perform <a href="https://github.com/MilesCranmer/PySR">symbolic regression</a> to infer a good rule of thumb. This could also be recasted into a rule of thumb relative to the bin width, which could be a useful metric for comparison (e.g.&nbsp;in <a href="#fig-bkde-bandwidth">Figure&nbsp;<span>7.12</span></a> shown earlier).</p>
<div id="fig-grad-errors" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/grad_errors.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.15: Absolute relative error in the bKDE gradient compared to the true distribution, calculated for a wide variety of bandwidths and sample sizes. Orange points indicate the lowest error across the rows of constant sample size to hint at the trend of a good bandwidth choice.</figcaption><p></p>
</figure>
</div>
</section>
<section id="other-differentiable-binned-density-estimates" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="other-differentiable-binned-density-estimates">Other differentiable binned density estimates</h4>
<p>In the INFERNO paper <span class="citation" data-cites="inferno">(<a href="references.html#ref-inferno" role="doc-biblioref">Castro and Dorigo 2019</a>)</span>, from which much inspiration was taken in general, they use a softmax function as a way to mimic binned output from the neural network, which would have an output dimensionality equal to the number of bins you want in your histogram. We can then think about each data point having a weight of 1, and having the softmax smoothly distribute that weight across the different bins. For a dataset <span class="math inline">\(\mathbf{x}\)</span> and a fixed neural network <span class="math inline">\(\mathbf{y}\)</span> with output nodes <span class="math inline">\(y_i\)</span> up to <span class="math inline">\(y_N\)</span>, the yield of bin <span class="math inline">\(i\)</span> in the histogram is calculated by summing the softmax contributions from each data point in that bin:</p>
<p><span class="math display">\[\begin{align}
\text{softmax histogram}_{\text{bin } i}(\mathbf{x}) &amp;= \sum_{\text{data }k} \text{softmax}(x_k, y_i) \\
&amp;= \sum_{\text{data }k} \frac{e^{y_{i}(x_k) / \tau}}{\sum_{j=0}^{\text{N}} e^{y_{j}(x_k) / \tau}}~,
\end{align}\]</span></p>
<p>where <span class="math inline">\(\tau\)</span> is a factor to tune how hard the slope of the softmax is, i.e.&nbsp;it has some analogy to the bandwidth about tuning the level of approximation. A drawback, however, is that the softmax used in tandem with a neural network does not come with an inherent notion of <em>ordering</em>; it’s going to be somewhat arbitrary in which bins events occupy, and the resulting plots are a little hard to interpret compared to regular histograms. Also, even the “hard” softmax with <span class="math inline">\(\tau \rightarrow \infty\)</span> is difficult to map to some other “true” histogram in which the bins follow Poisson-distributed counts.</p>
<p>As for other things, one could always do something like overlap sigmoid functions, or even make a KDE with a new histogram-like kernel. We’ll cap our imagination here though, and move onwards to the likelihood that this histogram is part of.</p>
</section>
</section>
<section id="differentiable-likelihood-construction" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="differentiable-likelihood-construction"><span class="header-section-number">7.2.4</span> Differentiable likelihood construction</h3>
<p>Now, I must confess, I have told you a bit of a white lie to set up the motivation here. The likelihood function as described in <a href="stat-practical.html#eq-hifabase">Equation&nbsp;<span>3.5</span></a> is indeed a-priori differentiable with respect to the histograms that make up the expectations. The problem is actually a <em>technical</em> one – we need to make this happen in code. As per our conversations on automatic differentiation, we know how to do this: we code up our program using a framework for automatic differentiation that has defined primitives and gradient rules. <code>pyhf</code> <span class="citation" data-cites="pyhf">Heinrich et al. (<a href="references.html#ref-pyhf2" role="doc-biblioref">2021</a>)</span> is the software package that brings this to life: the whole HistFactory prescription, all coded using a choice of autodiff backends, e.g.&nbsp;JAX, TensorFlow, and PyTorch. There’s honestly not too much else to say here; any further discussion would involve extremely niche and technical topics within the <code>pyhf</code> codebase, and all the error messages I saw over the years I worked on trying to hack things together. I’ll spare you that discussion (feel free to ask about it, or <a href="https://github.com/scikit-hep/pyhf/issues?q=is%3Aissue+author%3Aphinate+">browse the <code>pyhf</code> issues on the topic</a>), and we’ll move on to something a little more thesis-suited (though, what is a PhD if not niche and technical…).</p>
</section>
<section id="differentiable-test-statistics-profile-likelihood-ratio" class="level3" data-number="7.2.5">
<h3 data-number="7.2.5" class="anchored" data-anchor-id="differentiable-test-statistics-profile-likelihood-ratio"><span class="header-section-number">7.2.5</span> Differentiable test statistics (profile likelihood ratio)</h3>
<p>Recall from <a href="stat-practical.html#sec-asymptotics"><span>Section&nbsp;3.3</span></a> that when we’re constructing test statistics, we’re using the building block of the <em>profile likelihood ratio</em>, which we state once again as</p>
<p><span class="math display">\[
\lambda(x, \mu) = \frac{p\left(x|\mu,\hat{\hat{\theta}}(\mu)\right)}{p\left(x| \hat{\mu}, \hat{\theta}\right)}~.
\]</span></p>
<p>The variables <span class="math inline">\(\hat{\hat{\theta}}(\mu)\)</span> and <span class="math inline">\(\hat{\mu}, \hat{\theta}\)</span> are the result of two separate maximum likelihood fits. Are these differentiable? Well, yes – we can leverage the utility of automatic differentiation to trace each iteration of the optimization loop at runtime, and then do the corresponding gradient calculation by composing VJPs and the like. However, that could get really expensive as the number of iterations gets into the thousands, which isn’t too uncommon in practice. Do we have a way to get around this?</p>
<p>Thanks to the groundwork we set up in <a href="autodiff.html#sec-fixed-points"><span>Section&nbsp;5.3</span></a>, we worked out that we can take the gradient of <strong>fixed points</strong> (e.g.&nbsp;solutions to minimization algorithms) through a simple analytic formula in terms of the update step <span class="math inline">\(f\)</span>, the solution of the optimization problem <span class="math inline">\(\theta_0\)</span> (or <span class="math inline">\(\hat{\theta}\)</span>), and some particular value of <span class="math inline">\(\varphi=\varphi_0\)</span> that we used to define the objective:</p>
<p><span id="eq-fixed-point"><span class="math display">\[
\frac{\partial\theta_0}{\partial\varphi_0}= \left[I - \frac{\partial f}{\partial \theta_0} \right]^{-1} \frac{\partial f}{\partial \varphi_0}~.
\tag{7.5}\]</span></span></p>
<p>What does <span class="math inline">\(\varphi\)</span> mean here? It corresponds to the <em>same</em> <span class="math inline">\(\varphi\)</span> that we’re talking about in this section (the notation was not a coincidence)! Specifically, these would be the <em>analysis configuration parameters</em> (e.g.&nbsp;a combination of neural network parameters, observable binning, cutflow, etc.), which all <em>implicitly</em> determine the form of the likelihood. The language of “implicit” refers to the fact that we build the likelihood using the counts of the histograms for each physics process, with those counts in turn being influenced by <span class="math inline">\(\varphi\)</span>, but we do not explicitly denote the likelihood as <span class="math inline">\(p(x|\mu, \theta, \varphi)\)</span>, for instance.</p>
<p>In practice, we can implement this through moving the goalposts for what we call a primitive: for optimization loops like this, we can define that as a primitive of sorts, and then give it the known gradient as defined by <a href="#eq-fixed-point">Equation&nbsp;<span>7.5</span></a>. This is the kind of approach taken by <code>jaxopt</code> <span class="citation" data-cites="jaxopt">(<a href="references.html#ref-jaxopt" role="doc-biblioref">Blondel et al. 2021</a>)</span>, which is a library that’s used a few times in this thesis.</p>
</section>
<section id="differentiable-hypothesis-tests" class="level3" data-number="7.2.6">
<h3 data-number="7.2.6" class="anchored" data-anchor-id="differentiable-hypothesis-tests"><span class="header-section-number">7.2.6</span> Differentiable hypothesis tests</h3>
<p>What’s left to get us over the line to differentiating the result of a hypothesis test? Well, thanks to the formulae outlined in <a href="stat-practical.html#sec-asymptotics"><span>Section&nbsp;3.3</span></a>, to extract the expected (read: median) <span class="math inline">\(p\)</span>-value from the observed value of the test statistic <span class="math inline">\(t(x_0)\)</span>, we only need to do one last simple algebraic calculation:</p>
<ul>
<li>For the <strong>discovery <span class="math inline">\(p\)</span>-value</strong> with test statistic <span class="math inline">\(q_0\)</span>: <span class="math inline">\(p_0 = 1-\Phi(\sqrt{q_0})\)</span>.</li>
<li>For the <span class="math inline">\(p\)</span>-value associated with setting an <strong>upper limit</strong> using test statistic <span class="math inline">\(q_\mu\)</span>: <span class="math inline">\(p_\mu = 1-\Phi(\sqrt{q_\mu})\)</span>.</li>
<li>For the <span class="math inline">\(\text{CL}_s\)</span> <strong>method</strong>, we can just compose the <span class="math inline">\(p\)</span>-values from the previous step using different values of <span class="math inline">\(\mu\)</span> in <span class="math inline">\(q_\mu\)</span> as the point null: <span class="math inline">\(\text{CL}_s = p_{\mu=1} / (1-p_{\mu=0})\)</span>.</li>
</ul>
<p>All of these formulae are differentiable without any extra work, so we’re done!</p>
</section>
<section id="sec-inferno" class="level3" data-number="7.2.7">
<h3 data-number="7.2.7" class="anchored" data-anchor-id="sec-inferno"><span class="header-section-number">7.2.7</span> Bonus: Uncertainties on likelihood parameters</h3>
<p>Recall from <a href="stat-fundamentals.html#sec-fisher"><span>Section&nbsp;2.2.1</span></a> that the <em>Fisher information matrix</em> <span class="math inline">\(\mathcal{I}(\theta)\)</span> gives us access to the covariance matrix for maximum likelihood estimates, provided we’re in the asymptotic limit, through the Cramér–Rao bound:</p>
<p><span class="math display">\[
\Sigma_{\hat{\theta}}^{2} \geqslant [\mathcal{I}(\theta)]^{-1}~.
\]</span></p>
<p>Since <span class="math inline">\(\mathcal{I}(\theta)\)</span> is defined in terms of second-order derivatives of the log-likelihood – something that we’ve already made differentiable from a code perspective – we can then calculate the Fisher information using automatic differentiation. Moreover, since function transformations like the gradient operator are composable in automatic differentiation frameworks, this will itself be differentiable! This gives us access to many other inference-aware quantities that we can use as both diagnostics and as loss functions, including diagonal elements of the covariance matrix, which correspond to the individual uncertainties on each likelihood parameter. This approach was first explored by INFERNO <span class="citation" data-cites="inferno">(<a href="references.html#ref-inferno" role="doc-biblioref">Castro and Dorigo 2019</a>)</span>, from whom we take much inspiration from in this section.</p>
<p>Now, the fisher information involves a matrix filled with second derivatives of the likelihood, and so requires data and parameters to be evaluated as a number. One thing we can do in the HistFactory setting is use Asimov data, which would mean we’ll be able to know the best-fit parameter values already, and we can attempt to achieve the Cramér–Rao bound in <a href="stat-fundamentals.html#eq-cramer-rao">Equation&nbsp;<span>2.7</span></a> by evaluating at <span class="math inline">\(\mu=\mu'\)</span>, <span class="math inline">\(x=x_A(\mu')\)</span>. As to the choice of <span class="math inline">\(\mu'\)</span>, I’m not sure that it matters too much, as we’re always going to be at the best fit parameter value for <span class="math inline">\(\mu\)</span> (the likelihood shape itself isn’t affected by this, for instance), but I haven’t studied this in detail.</p>
</section>
</section>
<section id="putting-it-all-together" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="putting-it-all-together"><span class="header-section-number">7.3</span> Putting it all together!</h2>
<p>Now that we’ve enabled the differentiability of all the components layed out in <a href="#eq-neos">Equation&nbsp;<span>7.3</span></a>, we can see what happens when we use use the <span class="math inline">\(p\)</span>-value as out loss function, i.e.&nbsp;use gradients in <a href="#eq-analysis-chain-rule">Equation&nbsp;<span>7.4</span></a> to update the parameters <span class="math inline">\(\varphi\)</span>.</p>
<p>As a first example, we can look at the simple analysis from <a href="#sec-simple-anal"><span>Section&nbsp;7.1.1</span></a> as a candidate to test this out on! We were looking for the value of <span class="math inline">\(\phi\)</span> that corresponds to the best expected sensitivity to the signal model. Crucially, we needed to make sure that we accounted for the systematic uncertainty on the background <span class="math inline">\(\sigma_b\)</span>, which heavily influenced the resulting optimization. Let’s see if we can do that!</p>
<p>The results of training this setup to optimize <span class="math inline">\(\phi\)</span> with respect to the discovery <span class="math inline">\(p\)</span>-value can be seen in <a href="#fig-simple-opt">Figure&nbsp;<span>7.16</span></a>. Immediately, we can see that we’ve managed to find a point that minimizes the objective we care about, being able to incorporate uncertainty all the while! One thing I really like about this plot is the way it appeals to intuition – the expected counts that result from this procedure appear to be exactly at some medium compromise between signal to background ratio and uncertainty on the background. The acquired Swede within me would even go as far as to call it “lagom” – not too little, not too much; just the right amount<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<div id="fig-simple-opt" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/opt.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.16: Left: The resulting point from optimizing <span class="math inline">\(\phi\)</span> with gradient descent. Right: The histogram model at the solution of the optimization.</figcaption><p></p>
</figure>
</div>
<section id="a-quick-aside-on-inferno-vs-neos" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="a-quick-aside-on-inferno-vs-neos"><span class="header-section-number">7.3.1</span> A quick aside on INFERNO vs <code>neos</code></h3>
<p>My advocacy hereafter is to refrain from using <code>neos</code> or INFERNO methodology naming, since these methods differ only on small implementation details, the main one being the <em>choice of loss function</em>.</p>
<p>One interesting thing to note: we’re calculating the expected discovery <span class="math inline">\(p\)</span>-value using the asymptotic formulae outlined in <a href="stat-practical.html#sec-asymptotics"><span>Section&nbsp;3.3</span></a>. Minimising this <span class="math inline">\(p\)</span>-value corresponds to pushing the observed value of the <span class="math inline">\(q_0\)</span> test statistic as far to the right as possible (i.e.&nbsp;maximizing its value), which will trap smaller and smaller proportions of the distribution <span class="math inline">\(p(q_0 | \mu_0)\)</span> (smaller <span class="math inline">\(p\)</span>-values). Recall that <a href="stat-practical.html#eq-wald">Equation&nbsp;<span>3.6</span></a> states that we know an interesting fact about this test statistic: it’s approximately equal to <span class="math inline">\(\left((\mu_0 - \hat{\mu}(x))/\sigma_{\hat{\mu}}\right)^2\)</span>. Since we’re using Asimov data with <span class="math inline">\(\mu'=\hat{\mu}=1\)</span>, and probing a null of <span class="math inline">\(\mu_0=0\)</span>, the test statistic is actually an (inverse) estimate of the variance of <span class="math inline">\(\hat{\mu}\)</span>, which is being minimized during optimization! This has a lot of similarities with INFERNO, since both methods are effectively minimizing the same quantity, but estimated a different way; INFERNO uses the Fisher information estimate, and <code>neos</code> uses asymptotic formulae.</p>
<p>If we were to apply this same logic to calculating a <span class="math inline">\(p\)</span>-value (or a <span class="math inline">\(\mathrm{CL}_s\)</span> value) for upper limit setting, then we’d insead be using <span class="math inline">\(q_\mu\)</span>, and would typically examine Asimov data with <span class="math inline">\(\mu'=\hat{\mu}=0\)</span> (no signal) while looking at a null of <span class="math inline">\(\mu_0=1\)</span>. We would then still end up with the same relation of inverse proportionality to <span class="math inline">\(\sigma_{\hat{\mu}}^2\)</span>. Of course, the test statistics <span class="math inline">\(q_0\)</span> and <span class="math inline">\(q_\mu\)</span> differ conceptually in their definition, so there are likely going to be differences in practice if we used one or the other for optimization (but we would definitely expect a reduced uncertainty on <span class="math inline">\(\hat{\mu}\)</span> in either case). We’ll see these differences in practice later on.</p>
<p>Equipped with these systematic-aware (or more aptly, <em>inference</em>-aware) loss functions, we can now apply them to something a little more complicated.</p>
</section>
</section>
<section id="sec-neos" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="sec-neos"><span class="header-section-number">7.4</span> <code>neos</code>: End-to-End Optimized Summary Statistics for High-Energy Physics</h2>
<p>This section summarizes the work I’ve done in the paper <span class="citation" data-cites="neos">(<a href="references.html#ref-neos" role="doc-biblioref">Simpson and Heinrich 2021</a>)</span>. New follow-up studies will be shown in later sections.</p>
<p>The problem of reducing a whole set of physics quantities into a single number, or <strong>summary statistic</strong>, is not a new one in HEP. The reason for this is two-fold: inference in high-dimensional settings is computationally difficult, and the probability model defined by the underlying physics is intractable to explicitly compute. This leads to practice referenced a few times already, where we construct models via HistFactory, which are almost always based a single quantity, e.g.&nbsp;something like the invariant mass of the final state you’re interested in, or the output of a machine learning model. In the latter case, we’re typically concerned with optimizing for discriminating signal and background processes. However, we know from the previous sections that we can do much better by optimizing with respect to a <span class="math inline">\(p\)</span>-value, especially when we have significant systematic uncertainties to worry about.</p>
<p>To be more concrete: we’ll look at optimizing a neural network-based summary statistic for a simple HEP-like situation, including the construction of the uncertainty through interpolating between “up” and “down” variations of the background. We’ll refer to this workflow as <code>neos</code><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, with the full proposed pipeline shown in <a href="#fig-neos">Figure&nbsp;<span>7.17</span></a>.</p>
<div id="fig-neos" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/neos.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.17: Outline of the workflow proposed for <code>neos</code>.</figcaption><p></p>
</figure>
</div>
<section id="example-gaussian-blobs" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="example-gaussian-blobs"><span class="header-section-number">7.4.1</span> Example: Gaussian blobs</h3>
<p>Pretending our detector only outputs two physics variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, we’ll generate some toy data from different 2-D normal distributions (“Gaussian blobs”) for both signal and background, making sure they overlap a bit as to not be trivially separable. We’ll then also sample from Gaussian blobs on either side of the background, and treat these as “up” and “down” variations in the way described in <a href="stat-practical.html#sec-hifa-nps"><span>Section&nbsp;3.2.2</span></a>. We can see the result of sampling 10k points for each blob in <a href="#fig-data-space">Figure&nbsp;<span>7.18</span></a>.</p>
<div id="fig-data-space" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/data-space.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.18: Plot of 10k samples from toy distributions representing imagined signal, background</figcaption><p></p>
</figure>
</div>
<p>From here, things follow the diagram in <a href="#fig-neos">Figure&nbsp;<span>7.17</span></a>:</p>
<ul>
<li>We’ll pass the samples of <span class="math inline">\(x, y\)</span> values for each blob through a neural network, which turns each tuple of <span class="math inline">\((x, y)\)</span> into a single number <span class="math inline">\(f_\varphi(x, y)\)</span>, where <span class="math inline">\(f_\varphi\)</span> is our current network with parameters <span class="math inline">\(\varphi\)</span>.</li>
<li>We’ll then have four sets of values of <span class="math inline">\(f_\varphi\)</span> for each blob (signal, nominal background, and the up and down variations of the background), which we then turn into four histograms. During optimization, this histogram will be a bKDE as per <a href="#sec-bkde"><span>Section&nbsp;7.2.3</span></a> to make the final loss (<span class="math inline">\(\mathrm{CL}_s\)</span>) differentiable, but we’ll replace it with a regular histogram for calculating our evaluation metrics.</li>
<li>Using these histograms, we’ll build a HistFactory statistical model in exactly the same fashion as <a href="#eq-simplemodel">Equation&nbsp;<span>7.2</span></a> – with one parameter for the signal strength <span class="math inline">\(\mu\)</span>, and one nuisance parameter <span class="math inline">\(\gamma\)</span> that’s constructed by interpolating the shape variation between the histograms of the nominal, up, and down variations of the background.</li>
<li>We then build the appropriate test statistic based on this likelihood, and perform our hypothesis test – not on the observed data (we don’t have any), but on the Asimov dataset for that hypothesis (i.e.&nbsp;for a null of <span class="math inline">\(\mu=1\)</span>, we’re going to use the dataset that would result in <span class="math inline">\(\hat{\mu} = 1\)</span> when fitting the likelihood, which would just be the nominal counts <span class="math inline">\(s + b\)</span>).</li>
<li>The final step is producing the end result of that test (e.g.&nbsp;<span class="math inline">\(\mathrm{CL}_s\)</span>), then taking the gradient of that whole chain, which we’d use to update the parameters of the neural network <span class="math inline">\(\varphi\)</span>.</li>
</ul>
<p>We’ll feed data in using mini-batches, and hold out a group of points for each blob as a test set, which we use to calculate metrics and select the best model (normally we should never use the test set to choose a model, but the distributions are simple enough that there will be almost no macroscopic difference between train, validation, and test sets). The histogram yields are all divided by the number of data points per-batch, and then re-scaled to be on the order of tens of events, with different factors being applied to signal and background to put us in a more realistic regime (e.g.&nbsp;of low signal and high background).</p>
<p>In the graphs about to be shown, we’ll benchmark <code>neos</code> against optimization against some other loss functions:</p>
<ul>
<li><strong>Binary cross-entropy</strong> (BCE): This will try to discriminate signal versus nominal background samples, and will not be informed about the up/down samples during training.</li>
<li><strong>BCE with data augmentation</strong>: As above, but we indiscriminately label all of the background samples with one label instead of using just the nominal (this should be a very powerful baseline).</li>
<li><strong>INFERNO</strong>: As in <a href="#sec-inferno"><span>Section&nbsp;7.2.7</span></a>, we’ll take our loss to be the diagonal element of the inverse Fisher information that corresponds to the signal strength <span class="math inline">\(\mu\)</span>.</li>
</ul>
<section id="results-as-shown-in-the-neos-paper" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="results-as-shown-in-the-neos-paper">Results (as shown in the <code>neos</code> paper)</h4>
<p>The full set of hyperparameters for this study are:</p>
<ul>
<li>10000 data points, split evenly between all four blobs,</li>
<li>3-layer neural network of size (1024, 1024, 1),</li>
<li>Training with Adam optimiser, learning rate 1e-3,</li>
<li>Adam optimiser also used in maximum likelihood fits with learning rate 1e-3,</li>
<li><span class="math inline">\(m_\mathrm{s}=(-1, 1)\)</span>, <span class="math inline">\(m_\mathrm{b}=(2.5, 2)\)</span>, <span class="math inline">\(m_\mathrm{bup}=(-2.5, -1.5)\)</span>, <span class="math inline">\(m_\mathrm{bdown}=(1, -1)\)</span>,</li>
<li>Multiplicative histogram scale factors: signal scale=2, background scale=10, global scale=10,</li>
<li>ReLU activations, with sigmoid activation on the final layer,</li>
<li>15 epochs, with a batch size of 2000.</li>
</ul>
<p>Results from the training process using these hyperparameters are shown in <a href="#fig-neos-results">Figure&nbsp;<span>7.19</span></a>, where each curve is the average of that metric across 7 different training runs, all with unique random initializations of the neural network parameters. The figure has three plots, which we’ll cover from left to right. Note: these quantities are all computed on the same <em>test set</em> (unseen data), and use no approximations to hard operations in their calculation (which basically means the histogram is a normal one for <code>neos</code> and INFERNO).</p>
<div id="fig-neos-results" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/neos-results.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.19: Results from training neural networks using the four loss functions highlighted in the legend. Left: the expected <span class="math inline">\(\text{CL}_s\)</span>. Middle: The uncertainty on the signal strength <span class="math inline">\(\mu\)</span>. Right: The deviation from the nominal width of the nuisance parameter <span class="math inline">\(\gamma\)</span> that controls the background uncertainty.</figcaption><p></p>
</figure>
</div>
<p>The leftmost plot contains the expected <span class="math inline">\(\mathrm{CL}_s\)</span> for all four methods. We can see that the absolute lowest value of this is only attained by <code>neos</code>, which makes sense – we’re using this as the loss function itself. Both BCE methods reach a fairly low value quite quickly, which can be attributed to the fact that it’s not that difficult to isolate most of the signal in this example. Interestingly, INFERNO demonstrated far less stability with it’s <span class="math inline">\(\mathrm{CL}_s\)</span> value, with the different training runs having quite large variance in this quantity, causing their average to perform quite poorly. This says more about the interplay between the uncertainty on the signal strength and the <span class="math inline">\(\mathrm{CL}_s\)</span> than it does about what we consider “good performance” – I’ll come back to this in the discussion.</p>
<p>The middle plot is the uncertainty on the fitted value of the signal strength <span class="math inline">\(\sigma_{\hat{\mu}}\)</span>, as calculated through the Fisher information. Something I think is cool here is that <code>neos</code> learns to minimize this over time without any explicity prompting to do so (we’ll discuss more on this later). It’s no surprise that INFERNO does very well here, as again, it’s trained precisely to do so. BCE with augmentation also does very well, which is likely because we’ve ensured that anything that is non-signal looking, including possible variations on the background, is pushed to one side of the histogram, and the signal, which can be well isolated, is pushed to the other. Regular BCE, however, does okay initially, but will quickly overfit to the nominal signal/background discrimination if left to train for longer, which won’t care if there’s high background uncertainty in the signal bins.</p>
<p>The final plot on the right shows the squared deviation from the nominal uncertainty on the background nuisance parameter <span class="math inline">\(\gamma\)</span>, which we acquire through the appropriate diagonal term in the inverse Fisher information. In the likelihood modelling stage, this uncertainty also has an associated constraint term of <span class="math inline">\(\mathrm{Normal}(0 | \gamma, 1)\)</span>, where the “units” of <span class="math inline">\(\gamma\)</span> are chosen such that <span class="math inline">\(\gamma_{\mathrm{nom}}\)</span> sits at 0, and <span class="math inline">\(\gamma_{\mathrm{up}}/\gamma_{\mathrm{down}}\)</span> lie at +/- 1 respectively. If the standard deviation of the fitted value <span class="math inline">\(\hat{\gamma}\)</span> is different to 1, we then have a contradiction between the fitted model and the implied uncertainty from the constraint term. This is known as over/under-constraining the parameter (depending if the uncertainty is smaller/bigger than 1), and can be associated with model misspecification (although there are cases where it is perfectly reasonable to constrain the nuisance parameter depending on the nature of the measurement). Plotting this term (or <span class="math inline">\((1-\sigma_{\hat{\gamma}})^2\)</span> to just show the deviations) is then a useful diagnostic to see the learned behaviour of the observable with respect to the nuisance parameter. Training with <span class="math inline">\(\mathrm{CL}_s\)</span> doesn’t appear to introduce any pathologies in this regard, and in fact appears to further reduce dissonance between the constraint term and the Fisher information with more training. This is also the case for BCE with augmentation, but vanilla BCE and INFERNO don’t appear to exhibit this behaviour, and instead show some differences with the modelled standard deviation. The fact that BCE has no awarness of the background variations makes this less surprising, but I understand this less well for INFERNO at the time of writing (or even if it’s a problem at all).</p>
</section>
</section>
<section id="sec-neos-issues" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="sec-neos-issues"><span class="header-section-number">7.4.2</span> Practical issues</h3>
<p>Regardless of any results, one immediate concern that you may have thought of while I talked about <code>neos</code> was the scaling aspect. We can’t escape that one forward pass and one update step is computationally equivalent to two runs of the whole analysis inference chain (rembembering that gradients from autodiff are of the order of the forward pass to calculae). In practice, this seemed to be around ~3-4x an increase in performance time for an update to complete compared to BCE, but I’d expect this to increase more when applied to real analyses due to the complexity of the model, which has to be built each time for every set of new parameters<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, and also will have a much larger number of parameters, which will impact the speed of calculating the profile likelihood.</p>
<p>Another issue is that these inference-aware metrics require enough data to produce a reasonable reflection of the actual analysis model. With a very small batch size, this is impossible; for medium-size batches, it may be that some kind of proportional scaling needs to occur so the yields maintain the same relative sizes, as was done in practice during the Gaussian blobs example (not using these scale factors actually makes trainining unstable).</p>
</section>
</section>
<section id="whats-really-the-best-loss-function" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="whats-really-the-best-loss-function"><span class="header-section-number">7.5</span> What’s <em>really</em> the best loss function?</h2>
<p>The work done in making <span class="math inline">\(\mathrm{CL}_s\)</span> differentiable opened up a variety of new inference-aware losses as a by-product, including but not limited to:</p>
<ul>
<li><span class="math inline">\(\mathrm{CL}_s\)</span> (and its associated <span class="math inline">\(p\)</span>-values)</li>
<li><span class="math inline">\(p\)</span>-value for discovery (<span class="math inline">\(p_0\)</span>)</li>
<li>Quantities derived from the Fisher information matrix of the full HistFactory likelihood, such as:
<ul>
<li>uncertainty on the signal strength <span class="math inline">\(\sigma_{\mu}\)</span></li>
<li>deviations from the nominal nuisance parameter uncertainty, e.g.&nbsp;<span class="math inline">\((1-\sigma_{\hat{\gamma}})^2\)</span></li>
<li>the generalized variance, defined as the inverse determinant of the Fisher information</li>
</ul></li>
<li>Deviations from the nominal values of the nuisance parameters from control measurements (“pulls”)</li>
<li>…and <em>any algebraic combination of the above!</em></li>
</ul>
<p>Indeed, since all of these quantities can be calculated in a differentiable way, we can create a hybrid loss function using any of these components, such as <span class="math inline">\(a_1 \mathrm{CL}_s + a_2\sigma_{\mu}^2 + a_3\log{p_0} + \dots\)</span> etc. We can even view this through the lens of regularization, where we have one clear loss target, then introduce other components weighted with small linear coefficients to steer away from potentially undesirable pathologies.</p>
<p>Amongst those metrics already mentioned, one further example of a quantity that could serve this purpose is the empirical notion of the “<strong>Gaussianity</strong>” of a likelihood, which my colleague/supervisor Lukas Heinrich coined as the mean-squared difference across a grid of points between the learned HistFactory likelihood and a Normal distribution defined using the covariance implied by the (inverse) Fisher information matrix (remember the Cramér–Rao bound from <a href="stat-fundamentals.html#sec-fisher"><span>Section&nbsp;2.2.1</span></a>). This would essentially control the validity of the assumptions made when using the Fisher information to calculate uncertainties, as well as potentially reducing the chances of arriving at poorly-behaved likelihood shapes that happen to satisfy a low value of any particular metric.</p>
<p>But despite all of this, I find myself a little bit torn as to the real answer to the question posed in the section title: which loss function is <em>really</em> the best for physics analysis? This inquiry brings us one layer deeper philisophically, as it touches on a more delicate question: how do we actually gauge how good a physics result is? We’d maybe say something that aligns with our physics goals, e.g.&nbsp;the discovery significance, but the way we assess analyses is a little more nuanced than this in reality. One can see this by thinking about reviewing an analysis paper – we’re not just interested in the significance alone, but also things like the pull plots, the validity of the modelling assumptions, whether things are correlated in the right place, and probably many other things that I’m not thinking of. Moreover, these nuances would be even <em>more</em> important if the significance was high!</p>
<p>As a very preliminary exploration of this question, we’ll look at an example problem where the “best” solution is clear. We can then attempt to construct a loss function that is convex in the region of the optimum.</p>
<section id="sec-which-loss-model" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="sec-which-loss-model"><span class="header-section-number">7.5.1</span> A loss landscape interlude for a two-bin model</h3>
<p>The problem we’ll look at is as follows: similar to the Gaussian blob problem, we’ll define a two-bin HistFactory model with a signal strength <span class="math inline">\(\mu\)</span> and a three-point uncertainty on the background <span class="math inline">\(\gamma\)</span>. This model will be constructed from fixed nominal signal and background yields of <span class="math inline">\(s = [5, 11]\)</span> and <span class="math inline">\(b = [50, 50]\)</span>, with two free parameters <span class="math inline">\(u\)</span> and <span class="math inline">\(d\)</span> that control the up and down variations: <span class="math inline">\(b_{\mathrm{up}} = [50 + u, 50 -u ]\)</span>, <span class="math inline">\(b_{\mathrm{up}} = [50 - d, 50 + d ]\)</span>. The intuition for this is that any change in <span class="math inline">\(u\)</span> or <span class="math inline">\(d\)</span> will asymmetrically affect each bin by the same amount, so any optimization can’t focus on the gains from just one of the two bins. When both <span class="math inline">\(u\)</span> and <span class="math inline">\(d\)</span> are equal to 0, we’ll have <span class="math inline">\(b = b_{\mathrm{up}} = b_{\mathrm{down}}\)</span>, i.e.&nbsp;no systematic uncertainty on the background. We know that this would be the ideal solution, but what do our metrics have to say about it?</p>
<div id="fig-whichloss" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/metrics-title.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.20: A scan over the loss landscape for a two-parameter physics model, with each parameter having an asymmetric contribution to “up” and “down” variations of the background. The point [0,0] corresponds to no uncertainty on the nominal background prediction, and is highlighted with a red cross to indicate the target solution.</figcaption><p></p>
</figure>
</div>
<p><a href="#fig-whichloss">Figure&nbsp;<span>7.20</span></a> shows a scan over the loss landscape for many of the metrics we’re interested in, including the various <span class="math inline">\(p\)</span>-values, signal strength uncertainty, and a few bonus metrics that haven’t been explored (Gaussianity and generalized variance).</p>
<p>The first thing that I’ll guide your eyes to is the striking asymmetry in the <span class="math inline">\(\mathrm{CL}_s\)</span> and <span class="math inline">\(p_0\)</span> landscapes. For each individual metric, the asymmetry arises from the uneven signal distribution across the bins. The pattern we see is as follows: both metrics enjoy when <span class="math inline">\(u\)</span> and <span class="math inline">\(d\)</span> are approximately the same (which can be said for pretty much all the metrics). However, we then see the asymmetry: <span class="math inline">\(\mathrm{CL}_s\)</span> prefers <span class="math inline">\(u\)</span> and <span class="math inline">\(d\)</span> to be more negative (corresponding to up/down background variations below nominal in the first bin, and higher than nominal in the second), and <span class="math inline">\(p_0\)</span> prefers <span class="math inline">\(u\)</span> and <span class="math inline">\(d\)</span> to be more positive (up/down variations below nominal in the second bin, and higher in the first). As to why this is, my first thoughts are that the role of <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\mu=1\)</span> switches between the two metrics: for discovery, we’re testing a hypothesis of <span class="math inline">\(\mu=0\)</span> on Asimov data for <span class="math inline">\(\mu=1\)</span>, and for <span class="math inline">\(\mathrm{CL}_s\)</span>, we’re testing <span class="math inline">\(\mu=1\)</span> using Asimov data for <span class="math inline">\(\mu=0\)</span>. Then, in some way, the bin with the lower signal contribution (first bin) is more important for low <span class="math inline">\(\mathrm{CL}_s\)</span>, and the higher (second bin) is more important for a low discovery <span class="math inline">\(p\)</span>-value. This explanation certaintly appeals to intuition in some ways – particularly that the discovery <span class="math inline">\(p\)</span>-value wants the background variations as low as possible in the high-signal bin – but perhaps warrants examination through a more quantitative lens in future work.</p>
<p>One surprising artefact of the asymmetry between <span class="math inline">\(\mathrm{CL}_s\)</span> and <span class="math inline">\(p_0\)</span> is that a simple addition between them produces something fairly bowl-like around the point <span class="math inline">\(u = d = 0\)</span>, which we consider desirable from the perspective of an optimization procedure being able to achieve that minimum in practice. We can see this plot in the bottom-right of <a href="#fig-whichloss">Figure&nbsp;<span>7.20</span></a>, though it’s possible that one may want to match the scales of both quantities in practice by doing some weighted combination, which would make it so that one objective is not largely preferred over the other (e.g.&nbsp;here, something like <span class="math inline">\(\mathrm{CL}_s + 2p_0\)</span> would approximately match their absolute values). Of course, we should keep in mind that this apparently useful behaviour may vanish with more model complexity, and also requires fitting the same model twice for each forward pass if we’re calculating two profile likelihoods.</p>
<p>As for the other metrics, they generally become lower when <span class="math inline">\(u\)</span> and <span class="math inline">\(d\)</span> become more equal, corresponding to <span class="math inline">\(b_{\mathrm{up}} \approx b_{\mathrm{down}}\)</span>. Interestingly though, there isn’t much preference to the absolute values of the up and down variations, as long as they’re equal. This is a little counterintuitive, as we’d expect everything to benefit more in the case of <span class="math inline">\(b = b_{\mathrm{up}} = b_{\mathrm{down}}\)</span> (i.e.&nbsp;when <span class="math inline">\(u\)</span>, <span class="math inline">\(d\)</span> = 0), or at least have some kind of different result depending on the size of the variations compared to the nominal background prediction. However, one interesting pathology I discovered when looking more closely at these metrics is that they all have the <em>exact same values</em> along the line <span class="math inline">\(u=d\)</span>. This line also happens to be where the minimum values of the metrics lie, which is even true for <span class="math inline">\(\mathrm{CL}_s\)</span> and <span class="math inline">\(p_0\)</span>. It’s particularly hard to see this effect in <a href="#fig-whichloss">Figure&nbsp;<span>7.20</span></a>, so I’ve extrapolated just that line for all the metrics and plotted it in 1-D, shown in <a href="#fig-ud">Figure&nbsp;<span>7.21</span></a>. This is where Gaussianity can perhaps find utility: it’s the only quantity that varies asymmetrically along this line, and has a series of minima close to <span class="math inline">\(u = d = 0\)</span>. All other metrics retain exactly the same values for all models along the line, even those with values of <span class="math inline">\(b_{\mathrm{up}} = b_{\mathrm{down}}\)</span> that differ from the nominal by 10 in each bin. We’ll see little bit of this behaviour to prefer <span class="math inline">\(b_{\mathrm{up}} = b_{\mathrm{down}}\)</span> over <span class="math inline">\(b_{\mathrm{up}} = b_{\mathrm{down}} = b\)</span> in the next section, where we revisit the <code>neos</code> example of Gaussian blobs through the lens of examining the relationship between the metrics.</p>
<div id="fig-ud" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/equal-g.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.21: A projection of the line <span class="math inline">\(u = d\)</span> for all metrics, which are normalized by their maximum value. A small constant noise value is added to each metric in order to see all the lines at once.</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="gaussian-blobs-again" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="gaussian-blobs-again"><span class="header-section-number">7.6</span> Gaussian blobs, again</h2>
<p>Inspired by the studies in the previous section, I thought it would be useful to try the study from the <code>neos</code> paper a second time, but with some additional loss functions that we havent touched on yet (e.g.&nbsp;the discovery significance). Moreover, it may be illustrative to track the values of all the possible loss functions for each training strategy. In this way, we’ll be able to capture some idea of the relationships between quantities of interest – at least within the scope of the example itself.</p>
<p>We’ll look at the following choices for the training objective:</p>
<ul>
<li>BCE with data augmentation (serving again as a strong baseline)</li>
<li><span class="math inline">\(\mathrm{CL}_s\)</span></li>
<li><span class="math inline">\(p_0\)</span></li>
<li><span class="math inline">\(\sigma_{\mu}\)</span></li>
<li><span class="math inline">\(\mathrm{CL}_s\)</span> + <span class="math inline">\(p_0\)</span> (inspired by the previous section)</li>
</ul>
<p>The pipeline is exactly the same as in <a href="#sec-neos"><span>Section&nbsp;7.4</span></a>, but with slightly different hyperparameters. The only ones that differ are:</p>
<ul>
<li>5-layer neural network of size (128, 128, 128, 128, 1)<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
<li>More epochs (~100) with the same batch size of 2000 to view the learning process over a longer period of time (it looks like some curves in <a href="#fig-neos-results">Figure&nbsp;<span>7.19</span></a> would keep reducing with more training)</li>
<li>Average over nine random seeds (previously seven – just a time constraint on both accounts)</li>
<li>Bandwidth of 0.09 for the bKDE, found through trial and error by making it as small as possible while still producing stable training runs</li>
</ul>
<p>As an additional layer of complexity, we’ll look at how the different training strategies perform when using a lower and higher number of bins for the neural network observable, to see if that influences the efficacy of the methods. The bandwidth should then in theory be shrunk in proportion to match the smaller bin widths, though</p>
<section id="bin-observable" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="bin-observable"><span class="header-section-number">7.6.1</span> 5-bin observable</h3>
<section id="metrics" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="metrics">Metrics</h4>
<div id="fig-newneos-5bin-fixed" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/test_metricsfewnobins.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.22: Plots of the different metrics calculated on the test set for different training strategies using a 5-bin neural network observable. The results are averaged across 9 random seeds for the weight initializations. The scatter points on some of the curves represent the model that we would select in practice if using that training strategy (provided we decide to use the loss as the selection metric).</figcaption><p></p>
</figure>
</div>
<p>We’ll start by looking at the overall metrics when optimizing a 5-bin observable. These are shown in <a href="#fig-newneos-5bin-fixed">Figure&nbsp;<span>7.22</span></a>, where the circular points show the epoch where we would stop training and select that set of models across all the random seeds (being loose with the distiction between validation and test sets in this toy problem setting). To recap the differences to <a href="#fig-neos-results">Figure&nbsp;<span>7.19</span></a>: we’re using a slightly different neural network (deeper &amp; narrower), training for longer, and tracking all the different metrics for each training strategy.</p>
<p>By looking at the various metrics, we can see that training to minimze binary cross-entropy quickly converges to its best performance, since it’s not too difficult to separate the nominal signal and background samples from each other in data space (teal vs orange points). It’s worth pointing out that the small minima that appear early on in the three inference-aware metrics aren’t actually attained by the “optimal” solution that we decide on from looking at BCE alone. Even if we don’t train using those metrics, it then may still be worth tracking them to choose the best network.</p>
<p>When comparing BCE to other training strategies, note the difference in discovery <span class="math inline">\(p\)</span>-value – apparently we miss out on a <span class="math inline">\(p\)</span>-value that’s better by <em>six orders of magnitude</em> (a difference of <span class="math inline">\(\approx 4.75\sigma\)</span> for those that prefer significance) if we choose BCE over something like <span class="math inline">\(p_0\)</span> as an objective! It’s also interesting to note that there’s a very weak correlation between the models that are more inference-aware and their respective binary cross-entropies.</p>
<p>Another identifiable difference I’ll highlight is that training to minimize <span class="math inline">\(\sigma_{\mu}\)</span> is <em>much</em> better than it was in the <code>neos</code> paper! It also follows a curve that resembles that gained from optimizing <span class="math inline">\(\mathrm{CL}_s\)</span> for most of the metrics, which is much more in-line with expectations: remember that minimizing <span class="math inline">\(\mathrm{CL}_s\)</span> will also minimize some version of <span class="math inline">\(\sigma_{\mu}\)</span> too! So why were they so different in the <code>neos</code> paper? Well, the reason I seemed to stumble upon is that the wider and more shallow network of size (1024, 1024, 1) produces results with much higher variance for some reason when trained to optimize <span class="math inline">\(\sigma_{\mu}\)</span>. This is reflected in a statistic I didn’t show in the initial <code>neos</code> studies – the networks trained with different random seeds for the network parameters had very high variance! Why this occured for <span class="math inline">\(\sigma_{\mu}\)</span> in particular is unclear to me, but the results with the narrower, deeper network used here are far more stable, which will be seen again when we dive into some of the resulting models.</p>
<p>As to why the the Fisher information estimate of <span class="math inline">\(\sigma_{\mu}\)</span> minimizes <span class="math inline">\(\mathrm{CL}_s\)</span> much more than <span class="math inline">\(p_0\)</span>, there are a number of potential causes. Here, we evaluate the Fisher information using Asimov data with <span class="math inline">\(\mu'=\gamma'=1\)</span>, i.e.&nbsp;the nominal signal + background hypothesis; earlier I said it shouldn’t matter too much what this choice is, but it could play a factor that <span class="math inline">\(\mathrm{CL}_s\)</span> also uses this Asimov data configuration. It could also stem from the fact that <span class="math inline">\(q_0 \neq q_\mu\)</span>, but that’s pure speculation at this point – this should be studied further in future. The one definite takeaway is that all these metrics care about minimizing <span class="math inline">\(\sigma_{\mu}\)</span> in some fashion, even if their mutual relationships are more complicated.</p>
<p>Commenting on other features: the new player in the game is the discovery <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_0\)</span>, which performs pretty well in the three inference aware metrics. It’s curious to note that choosing <span class="math inline">\(\mathrm{CL}_s\)</span> or <span class="math inline">\(p_0\)</span> as a training strategy limits the performance in the other to a degree, though this is alleviated when training using their combination <span class="math inline">\(\mathrm{CL}_s + p_0\)</span> (as would be expected). There is a saying though – when one uses a metric as a training objective, it ceases to function well as a measure of performance, so we should take this all with a grain of salt and some lemon zest. In some ways this saying is only partially true here, as these metrics are calculated using a regular histogram instead of a bKDE, so they differ in a mild conceptual way. But despite that, all of <span class="math inline">\(\mathrm{CL}_s\)</span>, <span class="math inline">\(p_0\)</span>, and adding them together seem to perform identically with the value of <span class="math inline">\(\sigma_{\mu}\)</span> they end up with.</p>
<p>There’s a couple of good performances that are worth highlighting – optimizing with respect to <span class="math inline">\(\sigma_{\mu}\)</span> seems to match or beat using <span class="math inline">\(\mathrm{CL}_s\)</span> as the training goal within its own metric for one! It could be that it’s an easier metric to minimize in practice, and so it reaches its optimal value much faster. Though, neither <span class="math inline">\(\mathrm{CL}_s\)</span> nor <span class="math inline">\(\sigma_{\mu}\)</span> seem to be super great at optimizing for <span class="math inline">\(p_0\)</span> (but they handily beat binary cross-entropy). Using <span class="math inline">\(\mathrm{CL}_s + p_0\)</span> also ends up with a slightly better <span class="math inline">\(p_0\)</span> by a small amount than using <span class="math inline">\(p_0\)</span> as the objective, while not compromising on any of the other metrics.</p>
<p>As a supplement to the metrics we just examined, it’s interesting to see the types of observable that the network learns for each metric. For this, I’ve plotted the resulting histograms for each training strategy that were learned by the best-performing models over each random seed. These histograms are further augmented by plots of the value of the neural network observable across data space, where the contours used are exactly the same as the bin intervals; you can do a one-to-one comparison by looking at the points enclosed in one contour, and find the bin that corresponds to that interval, where you’ll see those points accumulated (after scale factors are applied). Many plots are ahead, and we could talk about them for a long time, but they’re mainly there to try to give you the maximally verbose version of this study – some brief summative comments are provided that point out some of the features I notice to aid your mental dissection.</p>
<p>Consistent shapes of learned histograms are found in most metrics, with <span class="math inline">\(p_0\)</span> showing the most variability. You’ll notice that sometimes the order of the bins appears to flip – that’s purely based on the nature of the random seed, and which side shows higher significance first during training. In many of the inference-aware metrics, we see a lot of bins that try to balance the up and down variations of the background, which were shown to be the best-case performance for our two-bin model in <a href="#sec-which-loss-model"><span>Section&nbsp;7.5.1</span></a>. Moreover, this is apparently a more important condition for <span class="math inline">\(\mathrm{CL}_s\)</span> and <span class="math inline">\(\sigma_{\hat{\mu}}\)</span> than it is for <span class="math inline">\(p_0\)</span>; the former tend to favor an even spread of equal up and down variations across all bins, while the latter seems to prefer isolated signal bins with no events from background or variations thereof.</p>
<p>In the neural network contours, e.g.&nbsp;in <a href="#fig-grid-5bin-discovery">Figure&nbsp;<span>7.29</span></a>, we can see again the effect of <span class="math inline">\(p_0\)</span> aggressively trying to isolate the signal within the contours, whetheras <span class="math inline">\(\mathrm{CL}_s\)</span> and <span class="math inline">\(\sigma_{\hat{\mu}}\)</span> prefer contours with balanced contributions from the up and down variations. The general pattern though in most cases is that the contours appear to curve around the signal for our inference aware metrics, whether as binary cross entropy just tries to draw a good dividing line between the orange (background) and teal (signal) blobs.</p>
<div id="fig-hists-5bin-bce" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-bce-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.23: Histograms from optimizing with respect to binary cross-entropy between signal and nominal background.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-5bin-discovery" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-discovery-5bin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.24: Histograms from optimizing with respect to the discovery <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_0\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-5nobin-CLs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-CLs-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.25: Histograms from optimizing with respect to the <span class="math inline">\(\mathrm{CL}_s\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-5bin-comb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-COMB-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.26: Histograms from optimizing with respect to a combination of discovery <span class="math inline">\(p\)</span>-value and <span class="math inline">\(\mathrm{CL}_s\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-5bin-poi-uncert" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-poi_uncert-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.27: Histograms from optimizing with respect to the Fisher information estimate of <span class="math inline">\(\sigma_{\hat{\mu}}\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-5bin-bce" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-bce-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.28: Contours of the neural network output from optimizing with respect to binary cross-entropy between signal and nominal background. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-5bin-discovery" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-discovery-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.29: Contours of the neural network output from optimizing with respect to the discovery <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_0\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-5bin-CLs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-CLs-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.30: Contours of the neural network output from optimizing with respect to the <span class="math inline">\(\mathrm{CL}_s\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-5bin-comb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-COMB-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.31: Contours of the neural network output from optimizing with respect to a combination of discovery <span class="math inline">\(p\)</span>-value and <span class="math inline">\(\mathrm{CL}_s\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-5bin-poi-uncert" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-poi_uncert-5nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.32: Contours of the neural network output from optimizing with respect to the Fisher information estimate of <span class="math inline">\(\sigma_{\hat{\mu}}\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="bin-observable-1" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="bin-observable-1"><span class="header-section-number">7.6.2</span> 20-bin observable</h3>
<p>Now we can see what happens when we provide a lot more bins to play with!</p>
<section id="metrics-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="metrics-1">Metrics</h4>
<div id="fig-newneos-20bin-fixed" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/test_metricsmanynobins.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.33: Plots of the different metrics calculated on the test set for different training strategies using a 20-bin neural network observable. The results are averaged across 9 random seeds for the weight initializations. The scatter points on some of the curves represent the model that we would select in practice if using that training strategy (provided we decide to use the loss as the selection metric).</figcaption><p></p>
</figure>
</div>
<p>The story doesn’t change too much with more bins, with all the training strategies maintaining their mutual relationships as discussed earlier. The only marked difference is that <span class="math inline">\(p_0 + \mathrm{CL}_s\)</span> outperforms <span class="math inline">\(p_0\)</span> alone much more clearly here, which is pretty interesting to think about.</p>
<p>I’ll also show the histograms and neural network contours in data space – there are some pretty funky ones for the high-bin case. You’ll see that the types of histogram model learned by the neural network fluctuate much more with this additional granularity provided by the new bins, especially for the hypothesis test-based metrics (seed 2 and 3 are particularly strange for <span class="math inline">\(p_0\)</span>).</p>
<p>For the contours themselves, there are many things to see here, but I’ll just point out one of my favourites: for seed 3 in <a href="#fig-hists-20nobin-CLs">Figure&nbsp;<span>7.36</span></a> and <a href="#fig-hists-20bin-discovery">Figure&nbsp;<span>7.35</span></a>, we see the network struggling to untie the systematic variations from the signal bins. However, for the same seed in <a href="#fig-hists-20bin-comb">Figure&nbsp;<span>7.37</span></a>, where we’re training on a combination of those metrics, the network seems to manage! No idea why this behaviour is there, and indeed it is just one seed. But I thought that was pretty cool.</p>
<div id="fig-hists-20bin-bce" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-bce-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.34: Histograms from optimizing with respect to binary cross-entropy between signal and nominal background.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-20bin-discovery" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-discovery-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.35: Histograms from optimizing with respect to the discovery <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_0\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-20nobin-CLs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-CLs-20bin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.36: Histograms from optimizing with respect to the <span class="math inline">\(\mathrm{CL}_s\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-20bin-comb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-COMB-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.37: Histograms from optimizing with respect to a combination of discovery <span class="math inline">\(p\)</span>-value and <span class="math inline">\(\mathrm{CL}_s\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-hists-20bin-poi-uncert" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-hist-models-poi_uncert-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.38: Histograms from optimizing with respect to the Fisher information estimate of <span class="math inline">\(\sigma_{\hat{\mu}}\)</span>.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-20bin-bce" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-bce-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.39: Contours of the neural network output from optimizing with respect to binary cross-entropy between signal and nominal background. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-20bin-discovery" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-discovery-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.40: Contours of the neural network output from optimizing with respect to the discovery <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_0\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-20bin-CLs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-CLs-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.41: Contours of the neural network output from optimizing with respect to the <span class="math inline">\(\mathrm{CL}_s\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-20bin-comb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-COMB-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.42: Contours of the neural network output from optimizing with respect to a combination of discovery <span class="math inline">\(p\)</span>-value and <span class="math inline">\(\mathrm{CL}_s\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
<div id="fig-grid-20bin-poi-uncert" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/new-grid-models-poi_uncert-20nobin.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;7.43: Contours of the neural network output from optimizing with respect to the Fisher information estimate of <span class="math inline">\(\sigma_{\hat{\mu}}\)</span>. The test set points are overlayed.</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="optimizing-binning-and-neural-network-simultaneously" class="level3" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="optimizing-binning-and-neural-network-simultaneously"><span class="header-section-number">7.6.3</span> Optimizing binning and neural network simultaneously</h3>
<p>One thing I also thought to try is, for a fixed number of bins, exploring what happens when the bin edges are made to be <em>part of the optimization itself</em>. Our free parameters are then <span class="math inline">\(\varphi = \left\{\varphi_{\mathrm{nn}}, \text{bin edges}\right\}\)</span>. To prevent the bin edges from being non-ascending, a <code>jax.numpy.where</code> statement was used to replace values that were larger than their neighboring edge with something just below it instead. As opposed to bin edges, we could have equivalently let the bin widths vary instead, and decide the last width as <span class="math inline">\(1-\sum_{i=0}^{\text{number of bins - 1}} \text{bin widths}_i\)</span>. In practice, this was found to be less stable when tried (often the sum of widths would exceed 1, and the last width becomes negative in that case). The endpoints <span class="math inline">\([0,1]\)</span> were taken as fixed to ensure there isn’t optimization that accounts for the bKDE spilling out outside that range. In hindsight, though, I think things would be fine without this restriction, especially since the best network is selected based on the the version of the loss with no approximations (i.e.&nbsp;a pipeline that uses a regular histogram with the optimized binning).</p>
<p>Results from this experiment are fairly similar to the fixed-bin case, and are shown in <a href="neos-extra.html"><span>Appendix&nbsp;A</span></a>. The most notable finding is that <span class="math inline">\(\sigma_{\hat{\mu}}\)</span> seemed to be the metric that made use of adapting the binning the most, but didn’t necessarily translate this to a big performance gain.</p>
</section>
</section>
<section id="whats-next" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="whats-next"><span class="header-section-number">7.7</span> What’s next?</h2>
<p>The first question that arises when reading this work for most – which mirrors accurately the same question I get when giving talks about this – is <em>how does it scale to optimize with a <span class="math inline">\(p\)</span>-value?</em> Great question; I wish I knew. I’ve not personally managed to apply this to a real use-case where this method could thrive (e.g.&nbsp;a physics analysis where systematic uncertainties serve as a bottleneck for performance). But if we were to do so, scaling will come with some challenges: the first being that the accuracy of the model construction per iteration is dependent on the batch size being large enough to faithfully represent the analysis. In practice, this was overcome by applying scale factors to the batches that normalized their event counts to something expected by the whole sample (in our toy case, we made the arbitrary choice of a 1/5 ratio between signal and background, with a normalization to around ~10 events or so). Moreover, the unavoidable truth already mentioned in <a href="#sec-neos-issues"><span>Section&nbsp;7.4.2</span></a> is that the cost of the forward pass + backward pass = ~<span class="math inline">\(\mathcal{O}(2\times \text{analysis cost})\)</span>, which may scale in complicated ways depending on the complexity of the model at hand. One would probably need to prune any workspace to only include systematic uncertainties that have been studied to impact the analysis result significantly.</p>
<p>A whole world of things could be targets for being made differentiable. As a simple extension to what’s already been shown here, one could imagine making upper limits differentiable in the same way as the profile likelihood; there’s no conceptual restriction, but since there’s an optimization procedure to determine the upper limit (find the value of the parameter that gives a certain <span class="math inline">\(p\)</span>-value), we can reuse the idea of implicit gradients that exist for functions with fixed points. There’s also a nice <a href="http://github.com/gradhep/relaxed/list_of_operations.md">set of operations that could benefit from being differentiable</a> curated by Kyle Cranmer, including things like sorting, statistical methods, and peer review (perhaps more relevant after AI take over the world – we can optimize their weights to help us get accepted at major conferences)<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. It’s possible that I’ve gotten around to implementing some of these in <a href="http://github.com/gradhep/relaxed"><code>relaxed</code></a> <span class="citation" data-cites="relaxed">(<a href="references.html#ref-relaxed" role="doc-biblioref">Simpson 2022a</a>)</span> by the time you read this, which is a differentiable toolbox of sorts that implements all of the advances that you’ve seen in this chapter.</p>
<p>While we’re on the topic, one particularly cool thing about <code>relaxed</code> is that it mimics the APIs of commonly used software tools in HEP. As an example, hypothesis tests are usually done with <a href="http://github.com/scikit-hep/pyhf"><code>pyhf</code></a> using the one-liner</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>pyhf.infer.hypotest(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    mu_0,  <span class="co"># null hypothesis for mu</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    data,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    test_stat,  <span class="co"># = q_mu or q_0</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And indeed, the same call works for <code>relaxed</code>, with the bonus being you can differentiate the result:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>relaxed.infer.hypotest(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    mu_0,  <span class="co"># null hypothesis for mu</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    data,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    test_stat,  <span class="co"># = q_mu or q_0</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    lr <span class="op">=</span> <span class="fl">1e-3</span>  <span class="co"># learning rate for fits (done with grad descent)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To see more of what this looks like in practice, I encourage you to check out the <a href="http://github.com/gradhep/relaxed">repository (e.g.&nbsp;the tests)</a>, a <a href="http://github.com/phinate/differentiable-analysis-examples">set of examples that I wrote</a> <span class="citation" data-cites="examples">(<a href="references.html#ref-examples" role="doc-biblioref">Simpson 2022b</a>)</span>, and my <a href="https://youtu.be/cOv7W-moO6k">PyHEP 2022 video tutorial</a>.</p>
<p>Beyond quantities that stem from statistical inference, differentiable simulation is another promising area that could allow simulator-in-the-loop optimization. An example could be tuning your simulator parameters to model data by gradient descent, or perhaps having a pipeline with a loss function that simulates physics on-the-fly based on learned parameters. Moreover, there has been a very interesting recent line of work that looks at making key physics processes differentiable, such as the calculation of matrix elements for scattering amplitudes <span class="citation" data-cites="madjax">(<a href="references.html#ref-madjax" role="doc-biblioref">Heinrich and Kagan 2022</a>)</span> and parton showering <span class="citation" data-cites="jaxshower">(<a href="references.html#ref-jaxshower" role="doc-biblioref">Nachman and Prestel 2022</a>)</span>. This is certainly an area to keep an eye on over the coming years.</p>
</section>
<section id="credits" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="credits"><span class="header-section-number">7.8</span> Credits</h2>
<p>Many thanks go to Lukas Heinrich for the inspiration, debugging help, and original proposal, and also to Tomasso Dorigo/Pablo de Castro for their initial assistance and work on INFERNO <span class="citation" data-cites="inferno">(<a href="references.html#ref-inferno" role="doc-biblioref">Castro and Dorigo 2019</a>)</span>, which lay lots of the groundwork for this topic. Thanks also to the other <code>pyhf</code> authors Matthew Feickert and Giordon Stark, and to Alex Held for his great notebook on differentiable cuts and other advice.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-jaxopt" class="csl-entry" role="doc-biblioentry">
Blondel, Mathieu, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan Hoyer, Felipe Llinares-López, Fabian Pedregosa, and Jean-Philippe Vert. 2021. <span>“Efficient and Modular Implicit Differentiation.”</span> <em>arXiv Preprint arXiv:2105.15183</em>.
</div>
<div id="ref-inferno" class="csl-entry" role="doc-biblioentry">
Castro, Pablo de, and Tommaso Dorigo. 2019. <span>“INFERNO: Inference-Aware Neural Optimisation.”</span> <em>Computer Physics Communications</em> 244 (November): 170–79. <a href="https://doi.org/10.1016/j.cpc.2019.06.007">https://doi.org/10.1016/j.cpc.2019.06.007</a>.
</div>
<div id="ref-deeplhc" class="csl-entry" role="doc-biblioentry">
Guest, Dan, Kyle Cranmer, and Daniel Whiteson. 2018. <span>“Deep Learning and Its Application to <span>LHC</span> Physics.”</span> <em>Annual Review of Nuclear and Particle Science</em> 68 (1): 161–81. <a href="https://doi.org/10.1146/annurev-nucl-101917-021019">https://doi.org/10.1146/annurev-nucl-101917-021019</a>.
</div>
<div id="ref-pyhf" class="csl-entry" role="doc-biblioentry">
Heinrich, Lukas, Matthew Feickert, and Giordon Stark. n.d. <em><span class="nocase">pyhf: v0.6.3</span></em> (version 0.6.3). <a href="https://doi.org/10.5281/zenodo.1169739">https://doi.org/10.5281/zenodo.1169739</a>.
</div>
<div id="ref-pyhf2" class="csl-entry" role="doc-biblioentry">
Heinrich, Lukas, Matthew Feickert, Giordon Stark, and Kyle Cranmer. 2021. <span>“Pyhf: Pure-Python Implementation of HistFactory Statistical Models.”</span> <em>Journal of Open Source Software</em> 6 (58): 2823. <a href="https://doi.org/10.21105/joss.02823">https://doi.org/10.21105/joss.02823</a>.
</div>
<div id="ref-madjax" class="csl-entry" role="doc-biblioentry">
Heinrich, Lukas, and Michael Kagan. 2022. <span>“Differentiable Matrix Elements with MadJax.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2203.00057">https://doi.org/10.48550/ARXIV.2203.00057</a>.
</div>
<div id="ref-jaxshower" class="csl-entry" role="doc-biblioentry">
Nachman, Benjamin, and Stefan Prestel. 2022. <span>“Morphing Parton Showers with Event Derivatives.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2208.02274">https://doi.org/10.48550/ARXIV.2208.02274</a>.
</div>
<div id="ref-relaxed" class="csl-entry" role="doc-biblioentry">
Simpson, Nathan. 2022a. <em><span class="nocase">relaxed: version 0.1.3</span></em> (version v0.1.3). <a href="https://doi.org/10.5281/zenodo.6330891">https://doi.org/10.5281/zenodo.6330891</a>.
</div>
<div id="ref-examples" class="csl-entry" role="doc-biblioentry">
———. 2022b. <em><span class="nocase">phinate/differentiable-analysis-examples</span></em> (version PyHEP2022 (0.1.3)). <a href="https://doi.org/10.5281/zenodo.7129990">https://doi.org/10.5281/zenodo.7129990</a>.
</div>
<div id="ref-neos" class="csl-entry" role="doc-biblioentry">
Simpson, Nathan, and Lukas Heinrich. 2021. <em><span class="nocase">neos: version 0.2.0</span></em> (version v0.2.0). <a href="https://doi.org/10.5281/zenodo.6351423">https://doi.org/10.5281/zenodo.6351423</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>We don’t have to use gradient based methods! They’re just very well implemented and studied, as well as enabling things like this paradigm.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>For non-uniform bin widths, an extension of the bKDE to non-uniform bandwidths could be interesting – one could keep the bin width/bandwidth ratio fixed for each bin, and if the event falls in a given bin, the resulting bandwidth from using that ratio is applied to that event. This would make the analogy between bin width and bandwidth more general in some ways, albeit at the cost of someone’s coding time.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>If you’re less of a holistic person and would prefer something more quantitative, you can see a real-life carving of the “lagom” amount in Lund, just outside one of the main university buildings.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Originally an acronym for neural end-to-end optimized statistics, but acronyms are annoying, so I don’t really make that explicit anymore. Hopefully the rest of this section will also convince you that we don’t need to get too caught up with naming anyway.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>I did some work on trying to cache these models and update them in-place – if you’re interested, see <a href="https://github.com/scikit-hep/pyhf/issues/1894">this <code>pyhf</code> issue</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Initially, this was chosen to be less wide to maybe slow down the learning process a touch, though the extra layers mitigates that to some degree. It turned out that this made the training much more stable for some reason (less variability in the metrics), so I kept it.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Thinking about it though, AI having a workshop about the workings of AI would be more like biology/philosophy. Perhaps this whole thesis is then unethical through this lens, exploiting and manipulating machines for our own curiosity. The complementary idea of inverting this exploitation is a rather dystopian one.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config);
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ml.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Machine learning</span></span>
      </a>
  </div>
  <div class="nav-page nav-page-next">
      <a href="./flow-interp.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Signal Model Interpolation using Normalizing Flows</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>

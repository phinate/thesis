<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Analysis in High-Energy Physics as a Differentiable Program - 6&nbsp; Machine learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./diffprog-hep.html" rel="next">
<link href="./autodiff.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Machine learning</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Analysis in High-Energy Physics as a Differentiable Program</a>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container">
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container">
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Fundamentals</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a>
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./physics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Physics background</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./stat-fundamentals.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Statistics, in theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./stat-practical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability and Statistics, in practice</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./diffprog.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Gradient descent</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./autodiff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic differentiation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./ml.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Machine learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container">
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Applications</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a>
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./diffprog-hep.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Analysis in High-Energy Physics as a Differentiable Program</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./flow-interp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Signal Model Interpolation using Normalizing Flows</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./sh.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Search for a heavy scalar particle <span class="math inline">\(X\)</span> decaying to a scalar <span class="math inline">\(S\)</span> and a Higgs boson, with final state <span class="math inline">\(b\bar{b}\gamma\gamma\)</span> in the ATLAS detector</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container">
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Appendices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a>
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
          <li class="sidebar-item">
  <div class="sidebar-item-container">
  <a href="./neos-extra.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Results when optimizing a neural network observable and binning simultaneously</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>

  <ul>
  <li><a href="#definitions" id="toc-definitions" class="nav-link active" data-scroll-target="#definitions"><span class="toc-section-number">6.1</span>  Definitions</a></li>
  <li><a href="#neural-networks-and-deep-learning" id="toc-neural-networks-and-deep-learning" class="nav-link" data-scroll-target="#neural-networks-and-deep-learning"><span class="toc-section-number">6.2</span>  Neural networks and deep learning</a>
  <ul class="collapse">
  <li><a href="#whats-a-layer-in-a-mlp" id="toc-whats-a-layer-in-a-mlp" class="nav-link" data-scroll-target="#whats-a-layer-in-a-mlp"><span class="toc-section-number">6.2.1</span>  What’s a “layer” in a MLP?</a></li>
  </ul></li>
  <li><a href="#sec-flows" id="toc-sec-flows" class="nav-link" data-scroll-target="#sec-flows"><span class="toc-section-number">6.3</span>  Normalizing flows</a>
  <ul class="collapse">
  <li><a href="#sec-trainflow" id="toc-sec-trainflow" class="nav-link" data-scroll-target="#sec-trainflow"><span class="toc-section-number">6.3.1</span>  Training a flow</a></li>
  <li><a href="#sec-maf" id="toc-sec-maf" class="nav-link" data-scroll-target="#sec-maf"><span class="toc-section-number">6.3.2</span>  Masked Autoregressive Flows</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Machine learning</span></h1>
</div>



<div class="quarto-title-meta">



  </div>


</header>

<p>The blanket term <strong>machine learning</strong> indicates a shift in mindset for how computers complete a given task. When presented with such a task, one may try to solve it through a pen and paper worked conceptual solution. It is then up to us to tell the computer – in excruciating detail in it’s own language – each of the individual steps needed to implement the solution we came up with. This is known as <em>programming</em> a computer. But what if there was a way to show the computer many examples of our problem, and use an algorithm to <em>learn</em> a good solution by updating some internal state?</p>
<p>That’s machine learning! We find some inspiration for this in a quote from the fantastically written essay in <span class="citation" data-cites="ml-essay">(<a href="references.html#ref-ml-essay" role="doc-biblioref">Samuel 1962</a>)</span>, which is stated in the context of comparing human-written programs to possibly learned ones:</p>
<blockquote class="blockquote">
<p>There are many mental processes that people are called upon to perform that cannot be, or at least have not been, reduced to a simple set of rules. Take the process of playing a game of chess, not of simply adhering to the rules of the game, but rather the process of playing a good game against an intelligent opponent. There are no known procedures for guaranteeing a win, and yet people learn to play the game and some few become very proficient. – Arthur L. Samuel</p>
</blockquote>
<p>The basic idea (also made reference to in that essay) is this: maintain some internal state – literally just a set of numbers, which could e.g.&nbsp;pick a pre-defined strategy based on a value – and then update that internal state in some way by checking the performance. This rather simple statement carries a lot of ambiguous ideas, such as</p>
<ul>
<li>a notion of internal state</li>
<li>some way to combine that state with data to produce a result</li>
<li>a performance metric to assess the result after applying the state</li>
<li>an update rule to improve the value of the state based on the performance</li>
</ul>
<p>These ideas form the cornerstone of machine learning approaches, and we’ll unpack them all in detail below. Before continuing though, it’s worth noting the distinction between <em>machine</em> learning and <em>deep</em> learning – the latter is a subset of the former, and refers to a particular paradigm involving complex neural networks. Machine learning makes no assumptions on the form of the machine itself.</p>
<section id="definitions" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="definitions"><span class="header-section-number">6.1</span> Definitions</h2>
<p>Machine learning methods follow a shared set of abstract steps: given a dataset, we</p>
<ul>
<li>define a <strong>model</strong> with <strong>parameters</strong> <span class="math inline">\(\varphi\)</span> (where the model is a way to combine <span class="math inline">\(\varphi\)</span> with the data)</li>
<li>construct a measure of performance for the model, called the <strong>objective function</strong></li>
<li><strong>fit</strong> the model to the dataset through some update rule</li>
<li>use the <em>learned</em> model to perform <strong>inference</strong> (apply the model to new data)</li>
</ul>
<p>We can see this workflow reflected in the API of modern software packages, such as <code>scikit-learn</code> <span class="citation" data-cites="sklearn">(<a href="references.html#ref-sklearn" role="doc-biblioref">Buitinck et al. 2013</a>)</span> and <code>keras</code> <span class="citation" data-cites="keras">(<a href="references.html#ref-keras" role="doc-biblioref">Chollet et al. 2015</a>)</span>. Using this framework and terminology, we’ll explore some useful models, reflecting on the developments that have occurred as a by-product of the modern era of computing.</p>
</section>
<section id="neural-networks-and-deep-learning" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="neural-networks-and-deep-learning"><span class="header-section-number">6.2</span> Neural networks and deep learning</h2>
<p>A model that would certainly be useful is one that can model the solution to any task at all. <strong>Neural networks</strong> are indeed this class of model; inspired by the way the brain handles the processing of information, they are proven to be <em>universal approximators</em>, i.e.&nbsp;given a <em>continuous function</em> <span class="math inline">\(g(\mathbf{x})\)</span>, where <span class="math inline">\(\mathbf{x}\)</span> is an arbitrary-length vector of real-valued inputs, there exists a value of parameters <span class="math inline">\(\varphi\)</span> such that a neural network <span class="math inline">\(f(\mathbf{x}, \varphi)\)</span> satisfies</p>
<p><span id="eq-approx"><span class="math display">\[
|g(\mathbf{x}) - f(\mathbf{x}, \varphi)| &lt; \epsilon~~~\forall~\mathbf{x},~\text{for }\epsilon&gt;0~.
\tag{6.1}\]</span></span></p>
<p>This is great! Though, it’s not necessarily this property that makes neural networks so popular, it’s more the fact that we can practically attain this performance. Said another way, it’s not just that there exists <span class="math inline">\(\varphi\)</span>, but that we can often find it in real life! This can be attributed both to the effectiveness of <em>gradient descent</em> as a learning algorithm, and the software/hardware that we have access to that breathes life into the training process.</p>
<p>So: what <em>is</em> a neural network in the first place?</p>
<p>At its simplest, a neural network is a sequence of location-scale transforms of the input data, with non-linear “activation” functions applied in-between to allow for non-linear modelling capabilities. This type of neural network is referred to as a <strong>multi-layer perceptron</strong> (MLP) or a <strong>feed-forward network</strong> (both namings given since I use them interchangeably in later sections). Each layer of an MLP represents a round of these computations. At its most complex, there’s a lot of funky ways to transform the data, including self-attention, convolutions, graph structure, and all sorts of other stuff. These types of specialized “architectures” are beyond the scope of what we’ll look at here, but are incredibly important for introducing inductive bias that helps to more efficiently identify useful information within the data.</p>
<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="fig-activations" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ml_files/figure-html/fig-activations-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;6.1: Commonly used activation functions, taken from the Python library JAX.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The ingredients to a MLP are the <strong>weights</strong> <span class="math inline">\(w\)</span>, the <strong>biases</strong> <span class="math inline">\(b\)</span>, and the <strong>activation functions</strong> <span class="math inline">\(\sigma\)</span>. The weights represent the scale transform, and the bias the location transform. On the other hand, the activation function plays the role of “bending” the output such that we can model non-linear effects, i.e.&nbsp;anything with realistic complexity. Examples of common activation functions can be found in <a href="#fig-activations">Figure&nbsp;<span>6.1</span></a>, where there are all sorts of flavors to choose from, each with their own quirks (ReLU and its variants have been the gold standard for some time).</p>
<p>You’ll typically see all this represented in a ball-and-stick diagram, e.g. <a href="#fig-ballandstick">Figure&nbsp;<span>6.2</span></a>. Each series of balls represents one set of computations with the weights, biases, and activation functions that are within that layer. The outputs from this are called activations (just to reference the application of the activation function). The thing we call a <strong>layer</strong> is then each set of parallel computations of this nature, which are then aggregated into the set of inputs to the next layer (if it exists, else it’s just the network output). Don’t get too hung up on this definition of the word “layer” though, it sort of breaks down when looking at modern architectures with very detailed computation steps.</p>
<div id="fig-ballandstick" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlp.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;6.2: The “ball-and-stick” representation of a MLP.</figcaption><p></p>
</figure>
</div>
<section id="whats-a-layer-in-a-mlp" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="whats-a-layer-in-a-mlp"><span class="header-section-number">6.2.1</span> What’s a “layer” in a MLP?</h3>
<p>Here’s a compact formula for a computation of a single layer. Given a set of <span class="math inline">\(n\)</span> activations from the previous layer (0th layer meaning just the data points), and <span class="math inline">\(k\)</span> neurons in layer <span class="math inline">\(i\)</span>, the output of applying the neurons to the activations to obtain the <span class="math inline">\(i+1\)</span>th layer is represented as a matrix equation:</p>
<p><span class="math display">\[
\textcolor[HTML]{17BECF}{
\underbrace{\left[\begin{array}{c}
a_0^{(i)} \\
a_1^{(i)} \\
\vdots \\
a_n^{(i)}
\end{array}\right]}_{\mathrm{activations for layer }i+1}}=\sigma\left(\textcolor[HTML]{FF7F0E}{\underbrace{\left[\begin{array}{cccc}
w_{0,0} &amp; w_{0,1} &amp; \cdots &amp; w_{0, n} \\
w_{1,0} &amp; w_{1,1} &amp; \cdots &amp; w_{1, n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
w_{k, 0} &amp; w_{k, 1} &amp; \cdots &amp; w_{k, n}
\end{array}\right]}_{\text{weight matrix}}}\textcolor[HTML]{1F77B4}{\underbrace{\left[\begin{array}{c}
a_0^{(i)} \\
a_1^{(i)} \\
\vdots \\
a_n^{(i)}
\end{array}\right]}_{\text{activations for layer }i}}+\textcolor[HTML]{2CA02C}{\underbrace{\left[\begin{array}{c}
b_0 \\
b_1 \\
\vdots \\
b_n
\end{array}\right]}_{\text{bias vector}}}\right)
\]</span></p>
<p><span class="math display">\[
\Rightarrow \textcolor[HTML]{17BECF}{\mathbf{a}^{(i+1)}} = \sigma\left(\textcolor[HTML]{FF7F0E}{\mathbf{W}}\textcolor[HTML]{1F77B4}{\mathbf{a}^{(i)}} + \textcolor[HTML]{2CA02C}{\mathbf{b}}\right)~,
\]</span></p>
<p>where applying the activation <span class="math inline">\(\sigma\)</span> is distributed to its elements, i.e. <span id="eq-layer"><span class="math display">\[
\sigma\left(\left[\begin{array}{l}
x \\
y \\
z
\end{array}\right]\right)=\left[\begin{array}{l}
\sigma(x) \\
\sigma(y) \\
\sigma(z)
\end{array}\right]~.
\tag{6.2}\]</span></span></p>
<p>This is essentially the definition of a neuron (the ball in the ball-and-stick diagram shown in <a href="#fig-ballandstick">Figure&nbsp;<span>6.2</span></a>): a neuron is the <span class="math inline">\(j\)</span>th function in a layer <span class="math inline">\(i\)</span> that maps the activations <span class="math inline">\(\mathbf{a}^{(i)}\)</span> from the previous layer into the <span class="math inline">\(j\)</span>th element of the <span class="math inline">\(i+1\)</span>th activation vector <span class="math inline">\(\mathbf{a}^{(i+1)}\)</span>, with a functional form as indicated in <a href="#eq-layer">Equation&nbsp;<span>6.2</span></a>. The sticks in that diagram would represent the elements of the weight matrix <span class="math inline">\(\mathbf{W}\)</span>, with missing connections between neurons <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> corresponding to zeroing out the <span class="math inline">\(w_{a,b}\)</span> term in the weight matrix.</p>
<p>If we put the weights and biases for each layer all into one vector of parameters, that’s what we’ve been calling <span class="math inline">\(\varphi\)</span>, which represents the entire internal state of a neural network. If we then bottle up the way we apply <span class="math inline">\(\varphi\)</span> to the data within the function <span class="math inline">\(f\)</span> – whether that be as simple as the MLP above or something more complex – we can compactly represent a neural network as <span class="math inline">\(f(\mathbf{x}, \varphi)\)</span> as above in <a href="#eq-approx">Equation&nbsp;<span>6.1</span></a>.</p>
<p>Since a neural network is a sequence of applications of <a href="#eq-layer">Equation&nbsp;<span>6.2</span></a>, it’s differentiable with respect to the parameters <span class="math inline">\(\varphi\)</span> (and even if it’s more complex, this differentiability is always made to be present). That means we can optimize our neural network with <strong>gradient descent</strong>, which we spent considerable time on in the previous section.</p>
<p>One extra thing to mention is the different type of architectures that go beyond this simple MLP framing. We can think about these architectures as a kind of inductive bias on the space of possible functions that could be learned, e.g.&nbsp;through some kind of specific manipulations that take advantage of the format of the input data (sequences, images, sets etc.). To highlight a few:</p>
<ul>
<li><p><strong>Convolutional neural networks</strong> <span class="citation" data-cites="cnn">(<a href="references.html#ref-cnn" role="doc-biblioref">Krizhevsky, Sutskever, and Hinton 2012</a>)</span> are one of the first types of domain-specific architecture, and manipulate an image through convolutional filters that measure local image features through things like pooling.</p></li>
<li><p><strong>Transformers</strong> <span class="citation" data-cites="transformers">(<a href="references.html#ref-transformers" role="doc-biblioref">Vaswani et al. 2017</a>)</span> perform fantastically well for sequential data (e.g.&nbsp;natural language), but have even shown generalization to other domains like images <span class="citation" data-cites="vit">(<a href="references.html#ref-vit" role="doc-biblioref">Dosovitskiy et al. 2020</a>)</span>. They use a mechanism called <em>self-attention</em> to extract information from sequential inputs, and are probably the most important architecture that exists at the time of writing in terms of their ability to generalize and scale.</p></li>
<li><p><strong>Deep sets</strong> <span class="citation" data-cites="deepsets">(<a href="references.html#ref-deepsets" role="doc-biblioref">Zaheer et al. 2017</a>)</span> is a method that incorporates the bias of the input data being an unordered collection. They have found use in e.g.&nbsp;particle physics <span class="citation" data-cites="deepsetsjets">(<a href="references.html#ref-deepsetsjets" role="doc-biblioref">Komiske, Metodiev, and Thaler 2019</a>)</span>, where objects like jets and their properties exist in unequal amounts across events, but without any specific ordering (though we’ve typically ordered them by <span class="math inline">\(p_T\)</span> and then treated them as a sequence in the past).</p></li>
<li><p><strong>Geometric deep learning</strong> <span class="citation" data-cites="geodl">(<a href="references.html#ref-geodl" role="doc-biblioref">Bronstein et al. 2021</a>)</span> generalizes a lot of the above, and casts things in the language of equivariances and graphs, spawning the idea of e.g.&nbsp;graph neural networks <span class="citation" data-cites="gnn">(<a href="references.html#ref-gnn" role="doc-biblioref">Scarselli et al. 2009</a>)</span>.</p></li>
</ul>
<p>There are countless other architectures, but we will focus on a particular neural network method (not necessarily an architecture) in the next section, as it makes up one of my applications, so we’ll spend a bit of extra time to sufficiently ground that work.</p>
</section>
</section>
<section id="sec-flows" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="sec-flows"><span class="header-section-number">6.3</span> Normalizing flows</h2>
<p>A <strong>normalizing flow</strong> is a trainable density estimator based on neural networks that admits both sampling and a tractable likelihood. Flows model a vector <span class="math inline">\(\mathbf{x} \in \mathbb{R}^D\)</span> from an underlying distribution <span class="math inline">\(p_X(\mathbf{x})\)</span> as a transformation <span class="math inline">\(\mathbf{x} = T(\mathbf{u})\)</span>, where <span class="math inline">\(\mathbf{u} \in \mathbb{R}^D\)</span> is a vector of samples drawn from a chosen distribution <span class="math inline">\(p_U(\mathbf{u})\)</span>. We refer to the data distribution <span class="math inline">\(p_X(\mathbf{x})\)</span> as the <strong>target distribution</strong> that we’re trying to model, and to <span class="math inline">\(p_U(\mathbf{u})\)</span> as the <strong>base distribution</strong> that we transform to do this. This base distribution is normally something simple like a normal distribution, which offers some guarantees as to making the flow a universal density approximator (details in <span class="citation" data-cites="flows">Papamakarios et al. (<a href="references.html#ref-flows" role="doc-biblioref">2019</a>)</span>).</p>
<p>How does this work? The transform <span class="math inline">\(T\)</span> is the key, and is the thing we’ll be training in practice. We start by pointing out the defining property of flows, which is the requirement that <span class="math inline">\(T\)</span> is both</p>
<ul>
<li><em>differentiable</em> (the Jacobian of the transformation <span class="math inline">\(J_T(\mathbf{u}) \in \mathbb{R}^{D\times D}\)</span> exists, where <span class="math inline">\(J_T(\mathbf{u})\)</span> is defined as in <a href="autodiff.html#eq-jacobian">Equation&nbsp;<span>5.1</span></a>)</li>
<li><em>invertible</em> (the inverse transformation <span class="math inline">\(T^{-1}(\mathbf{x})\)</span> exists).
<ul>
<li><span class="math inline">\(T^{-1}(\mathbf{x})\)</span> is also required to be differentiable for flows!</li>
</ul></li>
</ul>
<p>Given these properties, we can invoke the change of variables formula from <span class="math inline">\(X\)</span> to <span class="math inline">\(U\)</span>, which relates the target and base distributions by the determinant of the Jacobian matrix:</p>
<p><span class="math display">\[
p_X(\mathbf{x}) = p_U(\mathbf{u}) \left|\det{J_T(u)} \right|^{-1}.
\]</span></p>
<p>Here, <span class="math inline">\(\mathbf{u}\)</span> is calculated as the inverse transformation <span class="math inline">\(\mathbf{u} = T^{-1}(\mathbf{x})\)</span> since we want the exact <span class="math inline">\(\mathbf{u}\)</span> for our particular <span class="math inline">\(\mathbf{x}\)</span> when evaluating the likelihood. We’ve also exploited the fact that the determinant of the inverse of a matrix is the inverse of the determinant.</p>
<p>You may have noted our extra requirement that the inverse transform is also differentiable — the existence of the Jacobian <span class="math inline">\(J_{T^{-1}}(\mathbf{x})\)</span> lets us write the change of variables above in terms of only <span class="math inline">\(T^{-1}\)</span> and <span class="math inline">\(\mathbf{x}\)</span>:</p>
<p><span id="eq-flowlhood"><span class="math display">\[
p_X(\mathbf{x}) = p_U(T^{-1}(\mathbf{x})) \left|\det{J_{T{-1}}(\mathbf{x})} \right|.
\tag{6.3}\]</span></span></p>
<p>These equations form the basis for constructing a flow, where we implement the transform <span class="math inline">\(T\)</span> by using a neural network to control its parameters (e.g.&nbsp;a location-scale transform, where the location and scale are provided by a network).</p>
<p>One advantage of having a differentiable and invertible <span class="math inline">\(T\)</span> is that we can compose multiple transforms in a row, with the result itself being both differentiable and invertible. Specifically, we can write, for <span class="math inline">\(T=T_1 \circ T_2\)</span>:</p>
<p><span class="math display">\[
T^{-1} = (T_1 \circ T_2)^{-1} = T_2^{-1} \circ T_1^{-1}~,
\]</span> <span class="math display">\[
\det{J_T(\mathbf{u})} = \det{J_{T_1 \circ T_2}(\mathbf{u})} = \det{J_{T_2}(T_1(\mathbf{u}))}\det{J_{T_1}(\mathbf{u})}~.
\]</span></p>
<p>Knowing that we can stack transformations freely, we have a similar paradigm to neural networks, where stacking more “layers” (here, transforms) could bring about a more expressive model. This is the “flow” part of a normalizing flow: a series of samples from <span class="math inline">\(p_U\)</span> are flowing through a series of transforms <span class="math inline">\(T\)</span> to arrive at something like the target density <span class="math inline">\(p_X\)</span>. The “normalizing” part comes from going the other direction via <span class="math inline">\(T^{-1}\)</span>, where data samples are “normalized” back to the base distribution<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>There are many types of transforms one can choose to satisfy these requirements (which can be partitioned into a bijective “transformer” and a non-bijective “conditioner”), but I’ll omit everything but the one I used in <a href="#sec-maf"><span>Section&nbsp;6.3.2</span></a>, and direct you to <span class="citation" data-cites="flows">(<a href="references.html#ref-flows" role="doc-biblioref">Papamakarios et al. 2019</a>)</span> for a much more comprehensive review.</p>
<section id="sec-trainflow" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="sec-trainflow"><span class="header-section-number">6.3.1</span> Training a flow</h3>
<p>The goal is clear: we want to make our base distribution look like the target distribution. How do we quantify this?</p>
<p>Recall from <a href="stat-fundamentals.html#sec-KL"><span>Section&nbsp;2.2.2</span></a> that we have a way to measure the divergence between two probability distributions through the expected difference in log-likelihood under the true distribution (or approximate distribution, noting the asymmetric result depending on our choice). Denoting the predicted distribution from the flow as <span class="math inline">\(q_X(\mathbf{x}; \theta)\)</span> (where <span class="math inline">\(\theta\)</span> comprises both the parameters of the base density <span class="math inline">\(\gamma\)</span> and the parameters of the transform <span class="math inline">\(\phi\)</span>), and the target density as <span class="math inline">\(p_X(\mathbf{x})\)</span>, we can write this explicitly as</p>
<p><span class="math display">\[
D_{\mathrm{KL}}[p_X(\mathbf{x}) || q_X(\mathbf{x}; \theta)] = -\mathbb{E}_{p_X(\mathbf{x})}\left[\log q_X(\mathbf{x}; \theta)\right] + \mathrm{constant}
\]</span> <span class="math display">\[
\Rightarrow = -\mathbb{E}_{p_X}\left[\log p_U(T^{-1}(\mathbf{x} ;\phi); \gamma) + \log |\det J_{T^{-1}}(\mathbf{x}; \phi)|\right] + \mathrm{constant}~,
\]</span></p>
<p>where we’ve substituted our expression for the flow likelihood in <a href="#eq-flowlhood">Equation&nbsp;<span>6.3</span></a>.</p>
<p>This is a quantity we’d like to minimize, as to make <span class="math inline">\(p_X\)</span> and <span class="math inline">\(q_X\)</span> as “close” as possible. In practice, we’re likely going to have to substitute the expectation over the true (unknown) distribution with a Monte Carlo estimate using our data samples <span class="math inline">\({x_i}_{i=1}^{N}\)</span>, which turns this equation into</p>
<p><span class="math display">\[D_{\mathrm{KL}}[p_X(\mathbf{x}) || q_X(\mathbf{x}; \theta)] \approx-\frac{1}{N} \sum_{i=1}^N \log p_{\mathrm{u}}\left(T^{-1}\left(\mathbf{x}_i ; {\phi}\right) ; \gamma\right)+\log \left|\operatorname{det} J_{T^{-1}}\left(\mathbf{x}_i ; {\phi}\right)\right|+ \mathrm{constant}~.\]</span></p>
<p>This comes out to effectively minimizing the negative log-likelihood of the flow model on the data samples – we’re just fitting the model with maximum likelihood, as defined in <a href="stat-fundamentals.html#sec-mle"><span>Section&nbsp;2.3.1</span></a>! This is one example of how we can train a flow – we minimize this objective with respect to parameters <span class="math inline">\(\theta\)</span>, by e.g.&nbsp;gradient descent, since this is a differentiable expression in <span class="math inline">\(\theta\)</span>.</p>
</section>
<section id="sec-maf" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="sec-maf"><span class="header-section-number">6.3.2</span> Masked Autoregressive Flows</h3>
<p>A specific type of flow that we’ll encounter in the wild later is the <strong>masked autoregressive flow</strong> <span class="citation" data-cites="maf">(<a href="references.html#ref-maf" role="doc-biblioref">Papamakarios, Pavlakou, and Murray 2017</a>)</span>. The approach that this flow takes to density modelling is as follows:</p>
<p>When modelling a distribution across multiple random variables, one can break down their joint density into a product of conditional distributions through the probability chain rule as in <a href="stat-fundamentals.html#eq-prob-chain-rule">Equation&nbsp;<span>2.3</span></a>, and models these conditional distributions explicitly:</p>
<p><span class="math display">\[
p(x_1, \dots, x_N) = p(x_1)p(x_2 | x_1)p(x_3|x_2, x_1)\dots p(x_N | x_{N-1}, \dots, x_1)
\]</span> <span class="math display">\[
=\prod_{i=1}^Np(x_i|\mathbf{x}_{j&lt;i})
\]</span></p>
<p>Here, we’ve arbitrarily labelled our random variables <span class="math inline">\(x_i\)</span> with indicies <span class="math inline">\(i\)</span> from <span class="math inline">\(1\)</span> to <span class="math inline">\(N\)</span>, and use these to construct our conditional distributions. Note, however, that we could shuffle the order of our random variables, then reassign them the index of their place in the array, and the relation would still hold. Despite this, the only important thing is that each conditional distribution assigned to <span class="math inline">\(x_i\)</span> depends <em>only</em> on those <span class="math inline">\(x_j\)</span> for which <span class="math inline">\(j&lt;i\)</span>, <em>regardless of the initial variable ordering</em>. This is known as the <strong>autoregressive property</strong>.</p>
<p>One can model this relationship using a neural network in a <em>single forward pass.</em> By constructing a feed-forward network with equal input and output dimensionality, and assigning the same ordering to the input and output, we can simply drop (or <strong>mask</strong>) those connections for each output <span class="math inline">\(i\)</span> with all input variables that have index <span class="math inline">\(j&lt;i\)</span>. This way, there is no possible computational path between each output and the variables that come before that output in the ordering, meaning that the value of that output will be able to capture the nature of the relevant conditional <span class="math inline">\(p(x_i | \mathbf{x}_{j&lt;i})\)</span>. These aspects together form a <strong>masked, autoregressive</strong> network.</p>
<p>This idea was first used in <span class="citation" data-cites="made">(<a href="references.html#ref-made" role="doc-biblioref">Germain et al. 2015</a>)</span>, which used it to output the density directly in one forward pass by having the outputs correspond to the individual conditional distributions. However, to use this network in a flow, which transforms one distribution to another, we can instead use the outputs of the neural network to parametrize the transform <span class="math inline">\(T\)</span>. The result is known as a <strong>masked autoregressive flow</strong> (MAF), and was introduced in <span class="citation" data-cites="maf">(<a href="references.html#ref-maf" role="doc-biblioref">Papamakarios, Pavlakou, and Murray 2017</a>)</span>.</p>
<p>The MAF as I used it involved a fairly simple implementation of <span class="math inline">\(T\)</span> – a location scale transform:</p>
<p><span class="math display">\[
T(\mathbf{u}; \alpha, \beta) = \mathbf{\alpha} \cdot \mathbf{u} + \mathbf{\beta}~,
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\alpha}, \mathbf{\beta}\)</span> are the scale and location parameter vectors respectively. These are <em>vectors</em> because there’s one entry corresponding to each entry in <span class="math inline">\(\mathbf{u}\)</span>, where the individual parameters <span class="math inline">\(\alpha_i, \beta_i\)</span> are coming from the <span class="math inline">\(i\)</span>th output of a neural network (or more precisely, the <span class="math inline">\(i\)</span>th pair of outputs, since we have two values <span class="math inline">\(\alpha_i, \beta_i\)</span> for every one input <span class="math inline">\(u_i\)</span>), which has parameters itself <span class="math inline">\(\phi\)</span>. Training the flow is then done as in <a href="#sec-trainflow"><span>Section&nbsp;6.3.1</span></a>, with the masking mechanism from earlier in this section being put in place.</p>
<p>As a bonus, there’s a simple way to condition this transform on side information <span class="math inline">\(\mathbf{y}\)</span> that provides context: we can just add <span class="math inline">\(\mathbf{y}\)</span> as an extra input to the network (or multiple inputs if there’s more than one variable), and have it mix with every input, since each conditional distribution would also include <span class="math inline">\(\mathbf{y}\)</span>. We then have a MAF that can perform <strong>conditional density estimation</strong>, i.e.&nbsp;estimate <span class="math inline">\(p(x_1, \dots, x_N| \mathbf{y})\)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-geodl" class="csl-entry" role="doc-biblioentry">
Bronstein, Michael M., Joan Bruna, Taco Cohen, and Petar Velickovic. 2021. <span>“Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges.”</span> <em>CoRR</em> abs/2104.13478. <a href="https://arxiv.org/abs/2104.13478">https://arxiv.org/abs/2104.13478</a>.
</div>
<div id="ref-sklearn" class="csl-entry" role="doc-biblioentry">
Buitinck, Lars, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas Mueller, Olivier Grisel, Vlad Niculae, et al. 2013. <span>“<span>API</span> Design for Machine Learning Software: Experiences from the Scikit-Learn Project.”</span> In <em>ECML PKDD Workshop: Languages for Data Mining and Machine Learning</em>, 108–22.
</div>
<div id="ref-keras" class="csl-entry" role="doc-biblioentry">
Chollet, François et al. 2015. <span>“Keras.”</span> <a href="https://keras.io" class="uri">https://keras.io</a>.
</div>
<div id="ref-vit" class="csl-entry" role="doc-biblioentry">
Dosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, et al. 2020. <span>“An Image Is Worth 16x16 Words: Transformers for Image Recognition at Scale.”</span> <em>CoRR</em> abs/2010.11929. <a href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a>.
</div>
<div id="ref-made" class="csl-entry" role="doc-biblioentry">
Germain, Mathieu, Karol Gregor, Iain Murray, and Hugo Larochelle. 2015. <span>“<span>MADE:</span> Masked Autoencoder for Distribution Estimation.”</span> <em>CoRR</em> abs/1502.03509. <a href="http://arxiv.org/abs/1502.03509">http://arxiv.org/abs/1502.03509</a>.
</div>
<div id="ref-deepsetsjets" class="csl-entry" role="doc-biblioentry">
Komiske, Patrick T., Eric M. Metodiev, and Jesse Thaler. 2019. <span>“Energy Flow Networks: Deep Sets for Particle Jets.”</span> <em>Journal of High Energy Physics</em> 2019 (1). <a href="https://doi.org/10.1007/jhep01(2019)121">https://doi.org/10.1007/jhep01(2019)121</a>.
</div>
<div id="ref-cnn" class="csl-entry" role="doc-biblioentry">
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. <span>“ImageNet Classification with Deep Convolutional Neural Networks.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by F. Pereira, C. J. Burges, L. Bottou, and K. Q. Weinberger. Vol. 25. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf</a>.
</div>
<div id="ref-flows" class="csl-entry" role="doc-biblioentry">
Papamakarios, George, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. 2019. <span>“Normalizing Flows for Probabilistic Modeling and Inference.”</span> <a href="https://doi.org/10.48550/ARXIV.1912.02762">https://doi.org/10.48550/ARXIV.1912.02762</a>.
</div>
<div id="ref-maf" class="csl-entry" role="doc-biblioentry">
Papamakarios, George, Theo Pavlakou, and Iain Murray. 2017. <span>“Masked Autoregressive Flow for Density Estimation.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.1705.07057">https://doi.org/10.48550/ARXIV.1705.07057</a>.
</div>
<div id="ref-ml-essay" class="csl-entry" role="doc-biblioentry">
Samuel, Arthur L. 1962. <span>“Artificial Intelligence: A Frontier of Automation.”</span> <em>The Annals of the American Academy of Political and Social Science</em> 340: 10–20. <a href="http://www.jstor.org/stable/1033694">http://www.jstor.org/stable/1033694</a>.
</div>
<div id="ref-gnn" class="csl-entry" role="doc-biblioentry">
Scarselli, Franco, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. <span>“The Graph Neural Network Model.”</span> <em>IEEE Transactions on Neural Networks</em> 20 (1): 61–80. <a href="https://doi.org/10.1109/TNN.2008.2005605">https://doi.org/10.1109/TNN.2008.2005605</a>.
</div>
<div id="ref-transformers" class="csl-entry" role="doc-biblioentry">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> <em>CoRR</em> abs/1706.03762. <a href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</a>.
</div>
<div id="ref-deepsets" class="csl-entry" role="doc-biblioentry">
Zaheer, Manzil, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, and Alexander Smola. 2017. <span>“Deep Sets.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.1703.06114">https://doi.org/10.48550/ARXIV.1703.06114</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The naming is a bit extra, I know. But at least it’s not another play on “attention is all you need”.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config);
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./autodiff.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic differentiation</span></span>
      </a>
  </div>
  <div class="nav-page nav-page-next">
      <a href="./diffprog-hep.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Analysis in High-Energy Physics as a Differentiable Program</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>

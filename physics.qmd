---
title: "Physics background"
format:
  html:
    code-fold: true
    default-image-extension: svg
  pdf:
    default-image-extension: pdf
jupyter: python3
---


What makes up you and me? How do interactions on the smallest scales affect the way the universe was made and how it will end? Why does anything exist at all? Is anyone even reading this? If they do, but no-one is there to see them, will they make a sound?

At least two of these existential questions are explored by the scientific discipline known as **high-energy physics** (HEP). This term encompasses things like **particle physics**, **astrophysics**, and **cosmology**, which are a mix of studying things at the largest and smallest possible scales. We focus here on particle physics, which looks at the very, very small.

## The Standard Model

An innumerable number of particle physics results in the last 10 years or so have shown no signs of deviating from the predictions made from the **Standard Model** of particle physics, a theory proposed and developed by many scientists over many years @sm. We go over an extremely brief overview in the following paragraphs.

I am particles. So are you. Which particles? Textbooks would have us believe that we're made of "atoms", which in turn are made up of "protons, neutrons, and electrons". But like an onion, we have a layer deeper still, with protons and neutrons being made up of different **quarks**, which are another type of particle. Specifically, the proton contains two *up quarks* ($u$), and one down quark ($d$), which we denote using $uud$. The electric charge of $u$ is +2/3, and the charge of $d$ is -1/3, so the overall charge of the proton is +1. In contrast, the neutron has a composition of $udd$, and has an overall neutral electric charge of 0. The electron $e^-$, with overall charge of -1, seems to be more fundamental, and belongs to a species of particle known as **leptons**, which are posited to have no further components. Each lepton is associated with a corresponding neutrino -- a chargeless particle with unknown mass which we denote with $\nu_e$. We're slowly approaching botanical levels of nomenclature, so I'll summarize the rest of the particle types and naming in @fig-standard-model. For each fundamental particle listed, there also exists a corresponding **anti-particle**, which has the opposite sign for the charge (and other quantum numbers). We denote this with a bar for quarks (e.g. $\bar{b}$ is the anti $b$ quark), and for a change in sign for leptons (e.g. the positron $e^+$. It is not yet known whether there are anti-neutrinos, or if they are their own anti-particle.

It's worth noting that quarks are never observed standalone in a detector. Instead, they rapidly decay into sprays of collimated **hadrons** (particles containing quarks) by the process of hadronization. We refer to these structures as particle **jets**.

To be ever so slightly more precise in our construction, the Standard Model is a type of **quantum field theory**, which has a fundamental object defined over all of time and space called a *field*. These fields are described by equations that can be treated as waves, which are restricted to travel in discrete quanta of energy. These quanta are generally what we've been calling "particles", and also serve to mediate what we know as **forces**. In particular, when two bodies of matter as we know it feel a force, it is "carried" by a quantum of energy (i.e. a particle), and the bodies *exchange* the relevant particle, depending on the type of force. These forces, each corresponding to their own field, include:

- The **electromagnetic force**, carried by the **photon** $\gamma$
- The **weak force**, carried by three particles: the $W^+$, $W^-$, and $Z^0$ bosons
- The **strong force**, carried by the **gluon** $g$ (named for being the glue that keeps protons together)
- **Gravity**, which is not described by the Standard Model. Extensions propose a *graviton*, but this has no experimental evidence yet.

On that last point: it is unfortunate that such a well-tested theory does not adequately describe gravity, which, at the time of writing, seems to still be doing its thing. Moreover, Einstein's theory of General Relativity, which describes gravity, doesn't seem to fit well with all this particle talk, but it too is a very well-tested theory. This is one of many frustrating things about having the Standard Model triumph experimentally: we *know* it's not good enough alone^[I've heard water cooler talk about particle physicists even being upset at the Higgs discovery for this very reason -- a nail in the coffin for many other theories.]. As such, a great deal of other theories have been proposed that go *beyond the Standard Model* -- more on this later.

To top off our description of the Standard Model, we mention the **Higgs field**: it has a quantum of energy known as the **Higgs boson**, which is the mediator behind mechanisms that can be attributed as being responsible for giving particles *mass*. The particle discovered by the ATLAS and CMS experiments at CERN in 2012 is widely believed to represent the Higgs boson as proposed by the standard model @higgs (though, probing this question precisely is extremely important to see if there is anything non-standard-model about it).


## Properties of particles and their colliders

Due to the equivalence of mass and energy (think $E=mc^2$, or just $E=m$ in *natural units*), one could imagine the ability to create things with large mass, if we had enough energy to do so. That is precisely the idea behind **particle colliders**: we give particles a large amount of energy (i.e. they're traveling close to the speed of light), and then collide them so that they interact. These interactions, with sufficient energy, can then lead to the creation of heavier particles, provided that particle moves a little slower than the energy at which the particles that produced it collided. This process of collision is usually done through charged particles such as protons, because we can accelerate them using electric and magnetic fields.

How do we detect if we produced the particles we want? We can do this by analyzing data from the collision; for that, we need to surround areas of our collider with **detectors**, which collect all the by-products that splash out from the center of the collision. These detectors, along with some input from software, have the ability to *reconstruct* the tracks that (charged) particles leave in the detector, from which one can determine properties like the charge from the way the track curves. Additionally, there are modules that can measure the energy deposited from particles emerging from the collisions, which can be placed at different distances to measure particles with different lifetimes (short-lived particles that decay quickly won't ever make it past a certain distance before being totally absorbed by the detector itself).

Given this, we'll go over some of the properties that particles have while moving, and why they're useful for looking at the validity of physical theories.

From here, we will use the convention of **natural units**, which essentially absorbs constant factors of the speed of light $c$ and the Planck constant $\bar{h}$ into the units chosen. You will then see quantities quoted in **electron volts** (eV) with different prefactors as usual for the size (GeV = giga electron volts = $1\times 10^9$ eV etc.). 1 eV is a very small amount of energy indeed ($1.6 \times 10^{-19}$ Joules), with the center-of-mass energy of the Large Hadron Collider being $13.6$ TeV -- still much less than a sandwich (but I would support building a sandwich collider; see @meatball for an attempt of this nature, though physics results may vary).

### Kinematics

We start with **relativistic kinematics**, i.e. how things move when they're nearly at the speed of light. Objects like this are best described by talking about **spacetime**, which imparts an extra temporal dimension to the traditional three-vector for position in the form of a four-vector:

$$
x^\mu = (t, x, y, z) = (x_0, x_1, x_2, x_3)~.
$$

Equivalently, we can drop the index $\mu$ from upper to lower, and get the equivalent $x_\mu = (t, -x, -y, -z) = (x_0, -x_1, -x_2, -x_3)$ (choice of convention). This allows for the compact notation of dot products between four-vectors using summation notation:

$$
x^\mu y_\mu = y_\mu x^\mu  = x_0y_0 - [x_1y_1 + x_2y_2 + x_3y_3]~.
$$ {#eq-four-vec-prod}

This quantity is important, as it can be shown to be *Lorentz-invariant*, which means the value remains the same even if we change the reference frame we're in (i.e. we move in some way relative to the object). Using the four-vector for position, we can define a four-momentum:

$$
p^\mu = m \frac{dx^\mu}{d\tau}~,
$$

where $m$ is the object **rest mass**, and $\tau$ is the **proper time**, defined by applying the relativistic factor $\gamma$ to time as

$$
t = \gamma\tau;~~~ \gamma = \frac{1}{\sqrt{1-v^2}}
$$

for magnitude of the object's three-velocity $v = |\mathbf{v}|$. This leads to an equivalent notation of

$$
p^\mu = (E, \mathbf{p}); ~~~ E=\gamma m,~\mathbf{p}=\gamma m \mathbf{v}~.
$$

Using @eq-four-vec-prod, we can take the dot product of $p^\mu$ with itself:

$$
p^2 = p^\mu p_\mu = E^2 - |\mathbf{p}|^2~.
$${#eq-mom-dot}

We can exploit the fact that $p^2$ is invariant to its reference frame and examine one case in particular: a stationary body with 0 velocity but some mass will have a non-zero four-momentum $p^\mu = (m, 0)$. Then, we have $p^2 = m^2$, which we can set equal to @eq-mom-dot that holds generally:

$$
\Rightarrow E^2 - |\mathbf{p}|^2 = m^2~,
$${#eq-invariant-mass}

which is called the **energy-momentum relation**, and leads to the left-hand side being known as the **invariant mass** $s$, since it recovers the rest mass of a body in that body's rest frame. This then gives rise to the concept of the invariant mass of a system of bodies with four-momenta $p_1, p_2, ...$ -- their total momenta is $\sum_i p_i$, and the total invariant mass is then

$$
s_{1,2,...} = \left(\sum_i p_i\right)^2 ~,
$${#eq-invariant-mass-system}

which will involve terms in the energies and three-momenta of the different particles as per @eq-invariant-mass. This quantity will be particularly important when we come to the search for a new particle in the latter stages of the thesis.

### Quantifying collisions

An interaction between colliding particles (that usually produce some measurable detector output) is called a **scattering event**, or more simply just an **event**. To cause an event then, indeed, particles must collide. What's the chances of that happening? If we were instead talking about two tennis balls colliding, there would be an idea of a cross-sectional area influencing this, whereby if the tennis ball were to enter that region, collision of some variety would occur due to the balls being close enough, with the rate of this occurring being related to the size of that area. A similar quantity exists for particles colliding, which we call the **scattering cross-section** $\sigma$ (or just cross-section). The details on how one calculates a cross-section are more complicated for particles, but quantum field theory has exact rules for this that involve quantities called scattering amplitudes, and also performing an integral over the space of momenta of the initial state particles. I omit the details as they are beyond the scope of my work -- see e.g. @buckley Section 2.7 for more. We will go as far to state this: given a number of scattering events $N$ (every interaction between some set of colliding particles), the rate of these events occurring is directly proportional to the cross-section, i.e.

$$
\frac{dN}{dt} \propto \sigma~~~\Rightarrow \frac{dN}{dt} = \mathcal{L}(t) \sigma~,
$${#eq-cross-section}

where we've denoted the constant of proportionality as the **luminosity** $\mathcal{L}(t)$, which generally can be a function of anything to do with the structure of the colliding objects (e.g. beams of particles) at some time $t$. We can see that increasing $\mathcal{L}(t)$ increases the event rate; this leads to the analogy of beams of colliding particles being "brigher" with higher luminosity, hence the name.

We can also state that the overall cross-section of some collision is equal to the sum over the cross-sections for mutually exclusive physics processes $i$ (as to not double count): $\sigma = \sum_i \sigma_i$, and we have individual equations

$$
\frac{dN_i}{dt} = \mathcal{L}(t) \sigma_i~.
$$

The take-home from this is that for any physics process, the event rate in a collision will be a function of a term that dictates the underlying physics ($\sigma_i$) and a term that is influenced by beam structure ($\mathcal{L}(t)$). Moreover, we can define an overall **integrated luminosity** $L$ as a metric of cumulative beam "brightness" up to some time $T$ by integrating @eq-cross-section:

$$
L = \int_0^T \mathcal{L}(t) dt = N/\sigma~.
$$

The cross-section has units of area (m$^2$), and is usually quoted in *barns*, where 1 b = $10^{-28}$ m$^2$. Since $N$ is unitless, the luminosity then has units of inverse barns, which are usually quoted at the femto scale (fb$^{-1}$).

## Particle detectors

We'll say a few words on the detectors that are used to measure these particle collisions, with a focus on the ATLAS detector at CERN @ATLAS.

ATLAS is the name for both the detector that wraps around part of the beam pipe at the Large Hadron Collider, the experiment that it conducts, and for the collaboration of people that work on building the detector and analyzing the resulting data. The detector itself is split up into four concentric parts: the **inner tracking detector**, **electromagnetic calorimeter**, **hadronic calorimeter**, and the **muon detector**, which are in the toy schematic shown in @fig-detector. Each part has a different job, which is summarized in the following paragraphs.

![A toy schematic for the transverse cross-section of an imagined particle detector for collisions of two beams. The signatures different types of particles would leave are depicted within the detector.](images/detector-schematic){#fig-detector}

The inner detector tracks charged particles that leave *hits*; these come from things like ionization of a gas as the particle moves through, and having charged wires that collect the free electrons from the ionization. By trying to intelligently draw a line through these hits, e.g. by fitting a functional form, we can reconstruct the shape of the track. To measure the properties of charged particles emerging from collisions like the charge and momentum, we can look at the curvature of the track. To bend particles in the detector so that they have curvature, we need to apply a magnetic field that causes the particles to move in circular motion in the transverse plane (i.e. perpendicular to the direction of the beam). ATLAS does this by surrounding it's inner detector with a solenoid magnet (and toroidal magnets on the barrel and endcaps).

You'll have noticed there are two calorimeters -- this is because electrons and photons penetrate material much less deep than hadrons, so they're separated into two different parts. Calorimeters in general measure *energy deposits* by having the particles collide with some dense material, which causes energy loss in some way, and then interlacing that material with something that can collect information on the energy of the resulting products from traveling through the dense medium. The *electromagnetic calorimeter* is responsible for doing this for electrons and photons, where they undergo energy loss by scattering and Bremsstrahlung radiation. Likewise, the *hadronic calorimeter* does this for hadrons produced as a result of quarks hadronizing into particle jets, where their main source of energy loss is scattering processes.

The final part is the muon detector, which sits external to all other detectors, and is also a tracking detector like the inner detector. The muon passes through the inner detector and calorimeters, but typically will not lose much energy like other particles might from scattering or Bremsstrahlung. That means that if we have a tracking detector far from the beam pipe, it's likely that anything it picks up will be a muon.


### Kinematics, again

Using the information the detectors give us, we can summarize an event by the properties of the objects that the detector picked up as a result. We can think of an event as a list of particles with four-momenta, and one additional entry that has the missing four-momentum compared to the total inital proton four-momenta, which could include particles invisible to the detector like neutrinos. These four-momenta are typically transformed to a different set of coordinates that better fit with describing the geometry of the detector itself.

If we denote the beam axis as the $z$ direction, the $x$-$y$ plane is known as the **transverse plane**, which groups the three-momentum of a particle into $\mathbf{p} = (\mathbf{p}_T, p_z)$. One will often hear about the magnitude $p_T = |\mathbf{p}_T|$ being a quantity of interest, which is due to the fact that objects with high $p_T$ will likely be much easier to reconstruct and measure precisely, since they are not mixed up with all of the colliding proton beam debris in the $z$-direction. For this reason, we're actually not able to measure $p_z$ very well, and instead look to variables that are *invariant* to changes in velocity in the $z$ direction. One example of a quantity like this is the **rapidity**, defined as

$$
y = \frac{1}{2}\ln{\left(\frac{E+p_z}{E-p_z}\right)}~,
$$

which measures how "forward" (close to the +ve $z$ axis) or "backward" (close to the -ve $z$ axis) a particle lies. $y$ = 0 corresponds to no $z$ component of the momentum, and $\pm \infty$ means the momentum is aligned with the +ve and -ve $z$ direction respectively. Particle physicists often use the **pseudorapidity**, defined as

$$
\eta = -\ln{\left(\tan{\frac{\theta}{2}}\right)}~,
$$

which is equal to the rapidity for particles with energy $E$ much higher than their mass $m$. It's preferred since the polar angle $\theta$ between $z$ and the transverse plane is much easier to determine than $p_z$, for instance. We can thus fully specify a particle's position in the detector with the (pseudo)rapidity and the azimuthal angle $\phi$ between the $x$ and $y$ directions.


## Simulators

We are not able to perform our data analysis on collisions where we *know for sure* what produced them. If we could access this information, that would allow us to do many practice runs where we tune things to give us the best chance to discover the signal, if it was actually there. To this end, countless generations of particle physicists have worked on building robust **simulators** that can produce many Monte Carlo events (read: randomly sampled events from physics distributions). They work by calculating the different terms in an expansion as set out by quantum field theory responsible for the rates of physics processes, known as *perturbative field theory*, to a specified order in the expansion. This is what is referred to by phrases like *leading order* (LO) and next-to-leading order (NLO) -- it's the choice of terms you include in the perturbation calculation, which corresponds to choosing to include the different ways to produce that given final state you want to produce.

After simulating the physics processes themselves, we're not quite ready to jump in and optimize our analysis code, because we're not looking at something that mirrors what we'd expect from our detector. As an example, it's likely that our detector is only able to measure particle momenta up to a certain *resolution*, but we have access to the true values with no uncertainty. To change this, we can apply a layer of functions that attempt to *smear* the output, e.g. by sampling momentum from a normal distribution centered around the true value instead of using the true value directly, which should mimic the fact that we're inherently limited in the way we can measure these quantities in real life. Moreover, we won't be encountering the values of momentum -- we'll be getting electrical signals from a wire! We need to then do the additional step of **digitization**, which turns the physics quantities into things we'd expect from a detector, such as track hits and energy deposits.

Once we've done all that, we're free to then attempt to **reconstruct** the events just like we would for a regular detector (essentially building up particle four-momenta from track information), which allows us to make sure we don't do any better in getting the physics information than we would be able to in actuality. We can then use this information as the input for our physics analysis, and begin to optimize. The only difference is that there's a bias between the simulation and real data we may struggle to account for, but we trade off by having a label on each event that tells us which physics process it came from (i.e. signal or background). We can see this whole process depicted in @fig-simulator.

![A summary of the different workflow steps that are taken when simulating particle physics processes, including mirroring detector effects.](images/simulation){#fig-simulator}
